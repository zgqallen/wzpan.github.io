<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Eulerian Video Magnification | HaHack</title>
  <meta name="author" content="Joseph Pan">
  
  <meta name="description" content="欧拉影像放大算法（Eulerian Video Magnification）的原理和实现。">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="Eulerian Video Magnification"/>
  <meta property="og:site_name" content="HaHack"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/images/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="HaHack" type="application/atom+xml">
  
  <link rel="stylesheet" href="/dist/bootstrap.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/dist/bootstrap-responsive.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/dist/font-awesome.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/dist/style.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/dist/highlight.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/dist/sidenav.min.css" media="screen" type="text/css">  
  <link rel="stylesheet" href="/dist/responsive.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/dist/bubble.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/dist/google-fonts.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/dist/nprogress.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/timeline-comment.min.css" media="screen" type="text/css">
  
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

<!--  -->
<!--     <link href='http://fonts.googleapis.com/css?family=PT+Sans+Narrow|PT+Sans:400,400italic,700,700italic|Droid+Serif:400,400italic' rel='stylesheet' type='text/css'> -->
<!--     <link href='http://fonts.googleapis.com/css?family=Roboto' rel='stylesheet' type='text/css'> -->
<!--  -->
  
<script src="/dist/jquery-2.0.3.min.js"></script>


    <script src="/dist/videoGFW.min.js"></script>
	
	


    <script src="/js/github-comment.js"></script>
    <script src="/js/markdown.min.js"></script>
    <script src="/js/timeago.min.js"></script>
	<script src="/js/spin.min.js"></script>


</head>


<body data-spy="scroll" data-target=".toc">  
  <header id="header" class="inner"><div class="navbar navbar-inverse navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container">
            <a data-pjax class="brand" href="/">HaHack</a>
            <button type="button" class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <div class="nav-collapse collapse">
            <ul class="nav">				
			    
				   <li><a data-pjax href="/archive" title="所有文章归档"><i class="fa fa-archive"></i>Archive</a></li>				   			    			
				   <li><a data-pjax href="/categories" title="所有文章分类"><i class="fa fa-folder"></i>Categories</a></li>				   			    			
				   <li><a data-pjax href="/tags" title="所有文章标签"><i class="fa fa-tags"></i>Tags</a></li>				   			    			
				
				<li class="divider-vertical"></li>
			   	<li><a data-pjax href="/wiki" title="我的笔记库"><i class="fa fa-tasks"></i>wiki</a></li>				   
				
            </ul>			
			<ul class="nav navright">
				<li class="dropdown">
				<a data-pjax href="#" title="订阅本站" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-rss"></i>Subscribe <b class="caret"></b></a>
                                <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
				
				   <li role="presentation"><a role="menuitem" tabindex="-1" href="/atom.xml" title="使用 RSS 阅读器订阅 HaHack"><i class="fa fa-rss-square"></i>RSS</a></li>
				
				   <li role="presentation"><a role="menuitem" tabindex="-1" href="/wechat.html" title="订阅 HaHack 的公众平台"><i class="fa fa-qrcode"></i>WeChat</a></li>
				
				   <li role="presentation"><a role="menuitem" tabindex="-1" href="http://toutiao.io/u/147640" title=""><i class="fa fa-align-justify"></i>Toutiao</a></li>
				
                	        </ul>
				</li>
				
				<li><a data-pjax href="/about" title="关于我"><i class="fa fa-user"></i>About</a></li>				   				
   					  
            </ul>
            </div> <!-- nav-collapse collapse -->
        </div> <!-- container -->
     </div> <!-- navbar-inner -->
</div> <!-- navbar navbar-inverse -->
</header>
  <div class="container" id="container">
  	<div class="content">
    	 


	
		<div class="page-header">		
			<h1> Eulerian Video Magnification</h1>
		</div>    
	





<div class="row-fluid post">
	<!-- span -->
	
	<div class="span9">
	

	<!-- <div class="alert alert-error">
	<button type="button" class="close" data-dismiss="alert">&times;</button>
	<i class="fa fa-gift"></i> 过年了，<a href="/donate.html" target="_blank">给HaHack派个红包吧</a>！
</div> -->

	
		<div class="alert alert-success">
			<i class="fa fa-info-circle"></i> <p>欧拉影像放大算法（Eulerian Video Magnification）的原理和实现。</p>

		</div> <!-- alert -->
	
	
		<div class="alert alert-warning">
			<i class="fa fa-warning"></i> <p>请尊重他人劳动成果，不要直接将我的文字放入你的学术论文中。<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/deed.zh"><img title="知识共享许可协议" style="border-width: 0px; vertical-align: middle; display: inline; " src="http://i.creativecommons.org/l/by-nc-sa/3.0/80x15.png" original="http://i.creativecommons.org/l/by-nc-sa/3.0/80x15.png" class="nofancybox"></a></p>

		</div> <!-- alert -->
		   

		<!-- content -->
		<div class="mypage">
		<h2 id="引言">引言</h2>
<p>人类的视觉感知存在有限的感知域。对于超出感知域的变化，我们无法感知。然而，这类信号却可能蕴藏着惊人的秘密。</p>
<p>比如，血液循环使得人体的皮肤发生细微的周期性变化，这个裸眼无法感知的变化却和人的心率非常吻合。2011 年，MIT 的一个亚裔学生 Mingzhe Poh 就利用这个微弱的信号设计了一个“魔镜”<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>  —— 不仅能照出你的模样，还能测出你的心率。</p>
<p><img src="/images/eulerian-video-magnification/mirror.jpg" alt="Mingzhe Poh 的“魔镜”"></p>
<p>Mingzhe Poh 的这面神奇的镜子的原理是利用了血液在人体内流动时光线的变化 <sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup> ：心脏跳动时血液会通过血管，通过血管的血液量越大，被血液吸收的光线也越多，人皮肤表面反射的光线就越少。因此，通过对图像的时频分析就可以估算出心率。</p>
<p><img src="/images/eulerian-video-magnification/1839Kmo.png" alt="Cardiac pulse recovery methodology"></p>
<p>再比如，乐器之所以会发出声音，是因为它发声的部分在弹奏过程中发生了有规律的形变，而这个形变的振幅对应着乐器发声的响度，快慢对应着乐器的音高。微弱信号所蕴藏的信息量是如此重大，无怪乎禅语有云：</p>
<blockquote>
<p>一花一世界，一叶一菩提。</p>
</blockquote>
<p>既然如此，能否将影像中的这些肉眼观察不到的变化“放大”到裸眼足以观察的幅度呢？这就是本文将要重点讨论的问题。<a id="more"></a></p>
<p>在接下来的篇幅中，我将首先追溯最早的一个放大变化的实验——卡文迪许实验，然后引出适用于现代计算机的两种视角下的影像放大方法。这两种视角分别称为拉格朗日视角（Lagrangian Perspective）和欧拉视角（Eulerian Perspective）。最后我将重点探讨欧拉视角的算法实现细节。我所实现的一个欧拉影像放大算法程序<a href="https://github.com/wzpan/QtEVM" target="_blank" rel="external">在 Github 上开源</a>。</p>
<p><span class="block margin-div-outer"><span class="block margin-div-inner"><span class="block margin-note"><img src="/images/eulerian-video-magnification/Cavendish_Henry_signature.jpg" alt=" Henry Cavendish"><b>图 1</b>  Henry Cavendish</span></span></span></p>
<h2 id="最早的放大：卡文迪许扭秤实验">最早的放大：卡文迪许扭秤实验</h2>
<p>我所能追溯到的最早的将变化“放大”的实验是 1797 年卡文迪许（H.Cavendish）的经典实验——扭秤实验。卡文迪许实验是第一个在实验室里完成的测量两个物体之间万有引力的实验，并且第一个准确地求出了万有引力常数和地球质量。</p>
<p>实验的装置由约翰·米切尔设计，由两个重达350磅的铅球和扭秤系统组成。</p>
<p><img src="/images/eulerian-video-magnification/set.png" alt="卡文迪许所使用的装置"></p>
<p>卡文迪许用两个质量一样的铅球分别放在扭秤的两端。扭秤中间用一根韧性很好的钢丝系在支架上，钢丝上有个小镜子。用准直的细光束照射镜子，细光束反射到一个很远的地方，标记下此时细光束所在的点。用两个质量一样的铅球同时分别吸引扭秤上的两个铅球。由于万有引力作用。扭秤微微偏转。但细光束所反射的远点却移动了较大的距离。他用此计算出了万有引力公式中的常数 \(G\) 。</p>
<p>卡文迪许实验取得成功的原因，是将不易观察的微小变化量，转化（放大）为容易观察的显着变化量，再根据显着变化量与微小量的关系算出微小的变化量 。</p>
<p>卡文迪许的实验给了我们一个启示：放大变化，就是要解决以下两个问题：</p>
<p><div class="alert alert-success"><i class="fa fa-lightbulb-o"></i>  <ol>
<li><strong>何为“变”</strong> —— 如何找出不易观察的微小变化量；</li>
<li><strong>放大“变”</strong> —— 如何放大这个变化量，使之肉眼可见。</li>
</ol>
</div></p>
<p>不过，卡文迪许的这个实验需要借助一个庞大的扭秤装置，并不能直接用来放大影像中的变化。对于生活在二十一世纪的我们，最理想的方式当然是要借助计算机这个神器了。接下来将介绍两种现代的技术方案，能够让计算机为我们放大影像中细微的变化，从而使我们具有这样一对火眼金睛，去发现大自然隐藏的秘密。</p>
<h2 id="拉格朗日视角">拉格朗日视角</h2>
<p><span class="block margin-div-outer"><span class="block margin-div-inner"><span class="block margin-note"><img src="/images/eulerian-video-magnification/huineng.jpg" alt=" 六祖慧能"><b>图 2</b>  六祖慧能</span></span></span></p>
<blockquote>
<p>时有风吹幡动。一僧云：风动。一僧云：幡动。议论不已。能进曰：不是风动，不是幡动，仁者心动。一众骇然。</p>
</blockquote>
<p>六祖慧能在初见五祖的时候，恰逢有风吹来，吹得幡动。于是一个和尚说是风在动，另一个和尚说是幡在动，而慧能却一语道破：不是风动，也不是幡动，而是你的心在动。</p>
<p>看待一样东西，视角不同，得出的结论也就不同。正如看待生活中的“变”，视角不同，也会得到不同的结果。</p>
<p>所谓拉格朗日视角，就是从跟踪图像中感兴趣的像素（粒子）的运动轨迹的角度着手分析。打个比方，假如我们要研究河水的流速，我们坐上一条船，顺流而下，然后记录这条船的运动轨迹。</p>
<p><div class="alert alert-success"><i class="fa fa-lightbulb-o"></i>  <ol>
<li>何为“变” —— 感兴趣的像素点随着时间的运动轨迹，这类像素点往往需要借助人工或其他先验知识来辅助确定；</li>
<li>放大“变” —— 将这些像素点的运动幅度加大。</li>
</ol>
</div></p>
<p>2005 年，Liu 等人最早提出了一种针对影像的动作放大技术<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>，该方法首先对目标的特征点进行聚类，然后跟踪这些点随时间的运动轨迹，最后将这些点的运动幅度加大。</p>
<p><img src="/images/eulerian-video-magnification/1948ulu.png" alt="Motion Magnification"></p>
<p>然而，拉格朗日视角的方法存在以下几点不足：</p>
<ul>
<li>需要对粒子的运动轨迹进行精确的跟踪和估计，需要耗费较多的计算资源；</li>
<li>对粒子的跟踪是独立进行的，缺乏对整体图像的考虑，容易出现图像没有闭合，从而影响放大后的效果；</li>
<li>对目标物体动作的放大就是修改粒子的运动轨迹，由于粒子的位置发生了变化，还需要对粒子原先的位置进行背景填充，同样会增加算法的复杂度。</li>
</ul>
<h2 id="欧拉视角">欧拉视角</h2>
<p>不同于拉格朗日视角，欧拉视角并不显式地跟踪和估计粒子的运动，而是将视角固定在一个地方，例如整幅图像。之后，假定<strong>整幅图像都在变</strong>，只是这些变化信号的频率、振幅等特性不同，而我们所感兴趣的变化信号就身处其中。这样，对“变”的放大就变成了对感兴趣频段的析出和增强。打个比方，同样是研究河水的流速，我们也可以坐在岸边，观察河水经过一个固定的地方时的变化，这个变化可能包含很多和水流本身无关的成分，比如叶子掉下水面激起的涟漪，但我们只关注最能体现水流速的部分。</p>
<p><div class="alert alert-success"><i class="fa fa-lightbulb-o"></i>  <ol>
<li>何为“变” —— 整个场景都在变，而我们所感兴趣的变化信号藏在其中；</li>
<li>放大“变” —— 通过信号处理手段，将感兴趣的信号分离，并进行增强。</li>
</ol>
</div></p>
<p>2012 年， Wu 等人从这个视角着手，提出了一种称为欧拉影像放大技术（Eulerian Video Magnification）的方法<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>，其流程如下：</p>
<ol>
<li><strong>空间滤波</strong>。将视频序列进行金字塔多分辨率分解；</li>
<li><strong>时域滤波</strong>。对每个尺度的图像进行时域带通滤波，得到感兴趣的若干频带；</li>
<li><strong>放大滤波结果</strong>。对每个频带的信号用泰勒级数来差分逼近，线性放大逼近的结果；</li>
<li><strong>合成图像</strong>。合成经过放大后的图像。</li>
</ol>
<p><img src="/images/eulerian-video-magnification/19487v0.png" alt="Overview of the Eulerian video magnification framework"></p>
<p>在下一节我们将重点探讨 Wu 等人所提出的这种线性的欧拉影像放大技术。之所以加上“线性”这个修饰词，是因为 Wadhwa 等人在 2013 年对这项技术进行了改进，提出了基于相位的影像动作处理技术<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>。基于相位的欧拉影像放大技术在放大动作的同时不会放大噪声，而是平移了噪声，因而可以达到更好的放大效果。不过对它的讨论超出了本文的篇幅，感兴趣的读者可以自己找来他们的 paper 阅读。</p>
<h2 id="算法细节">算法细节</h2>
<h3 id="空间滤波">空间滤波</h3>
<p>如前面所说，欧拉影像放大技术（以下简称 EVM ）的第一步是对视频序列进行空间滤波，以得到不同的<a href="http://zh.wikipedia.org/zh-cn/%E7%A9%BA%E9%97%B4%E9%A2%91%E7%8E%87" target="_blank" rel="external">空间频率</a>的基带。这么做是因为：</p>
<ol>
<li>有助于减少噪声。图像在不同空间频率下呈现出不同的SNR（信噪比）。一般来说，空间频率越低，信噪比反而越高。因此，为了防止失真，这些基带应该使用不同的放大倍数。最顶层的图像，即空间频率最低、信噪比最高的图像，可使用最大的放大倍数，下一层的放大倍数依次减小；</li>
<li>便于对图像信号的逼近。空间频率较高的图像（如原视频图像）可能难以用泰勒级数展开来逼近。因为在这种情况下，逼近的结果就会出现混淆，直接放大就会出现明显失真<span class="margin-note-marker"><sup>1</sup></span> <span class="block margin-div-outer"><span class="block margin-div-inner"><span class="block margin-note"><span class="margin-note-marker">1</span>对于这种情况，论文通过引入一个空间波长下限值来减少失真。如果当前基带的空间波长小于这个下限值，就减少放大倍数。 </span></span></span> 。</li>
</ol>
<p>由于空间滤波的目的只是简单的将多个相邻的像素“拼”成一块，所以可以使用<a href="/wiki/opencv-image.html#%E4%BD%8E%E9%80%9A%E6%BB%A4%E6%B3%A2">低通滤波器</a>来进行。为了加快运算速度，还可以顺便进行<a href="/wiki/opencv-image.html#%E4%B8%8B%E9%87%87%E6%A0%B7">下采样</a>操作。熟悉图像处理操作的朋友应该很快可以反应出来：这两个东西的组合就是金字塔。实际上，线性的 EVM 就是使用拉普拉斯金字塔或高斯金字塔来进行多分辨率分解。</p>
<h3 id="时域滤波">时域滤波</h3>
<p>得到了不同空间频率的基带后，接下来对每个基带都进行时域上的带通滤波，目的是提取我们感兴趣的那部分变化信号。</p>
<p>例如，如果我们要放大的心率信号，那么可以选择 0.4 ～ 4 Hz （24～240 bpm ）进行带通滤波，这个频段就是人的心率的范围。</p>
<p>不过，带通滤波器有很多种，常见的就有理想带通滤波器、巴特沃斯（Butterworth）带通滤波器、高斯带通滤波器，等等。应该选择哪个呢？这得根据放大的目的来选择。如果需要对放大结果进行后续的时频分析（例如提取心率、分析乐器的频率），则应该选择窄通带的滤波器，如理想带通滤波器，因为这类滤波器可以直接截取出感兴趣的频段，而避免放大其他频段；如果不需要对放大结果进行时频分析，可以选择宽通带的滤波器，如 Butterworth 带通滤波器，二阶 IIR 滤波器等，因为这类滤波器可以更好的减轻振铃现象。</p>
<p><img src="/images/eulerian-video-magnification/1948IBv.png" alt="Temporal filters used in Wu's paper"></p>
<h3 id="放大和合成">放大和合成</h3>
<p>经过前面两步，我们已经找出了“变”的部分，即解决了何为“变”这个问题。接下来我们来探讨如何放大“变”这个问题。</p>
<p>一个重要的依据是：<strong>上一步带通滤波的结果，就是对感兴趣的变化的逼近</strong>。接下来将证明这个观点。</p>
<p>这里以放大一维的信号为例，二维的图像信号与此类似。</p>
<p>假定现在有个信号 \(I(x, t)\) ，在任意时刻 \(t\) ，有：</p>
<p><div class="label-anchor"><span>eq: 1 »</span></div>\[ \begin{aligned} I(x,t) &amp; = f(x+\delta(t)) &amp; , t >0 \\ I(x,0) &amp; = f(x) &amp; , t=0 \end{aligned} \]</p>
<p>其中，\(\delta(t)\) 是变化信号，在本例中就是一个位移函数。</p>
<p>我们希望得到这个变化放大 \(\alpha\) 倍后的结果，即：</p>
<p><div class="label-anchor"><span>eq: 2 »</span></div> \[ \hat{I}(x,t)=f(x+\color{red}{(1+\alpha)}\delta (t)) \]</p>
<p>为了将变化的部分分离出来，我们用一阶泰勒级数展开来逼近公式 1 表示的信号<span class="margin-note-marker"><sup>2</sup></span> <span class="block margin-div-outer"><span class="block margin-div-inner"><span class="block margin-note"><span class="margin-note-marker">2</span>想起了高数老师在第一节课所说的话：高等代数，也就是微积分，研究的就是一个字：“变”。 </span></span></span> ：</p>
<p><div class="label-anchor"><span>eq: 3 »</span></div> \[I(x,t)\approx f(x)+\color{blue}{\delta(t)\frac{\partial f(x)}{\partial x}}\]</p>
<p>公式 2 中标蓝的部分恰好就是变化的部分，而这个部分又和上一步的带通滤波有着重要的联系。下面分两种情况讨论。</p>
<h4 id="理想情况">理想情况</h4>
<p>我们先考虑一种理想情况：假如所有的变化信号 \(\delta(t)\) 的频率范围恰好是我们进行带通滤波时所选的频带范围，那么带通滤波结果 \(B(x,t)\) 应该恰好等于公式 2 中标蓝的部分，即：</p>
<p><div class="label-anchor"><span>eq: 4 »</span></div> \[B(x,t)=\color{blue}{\delta(t)\frac{\partial f(x)}{\partial x}}\]</p>
<p>对公式 2 所逼近的信号进行放大，就是将这个变化的部分乘以一个放大倍数 \(\alpha\) ，再加回原来的信号中。即：</p>
<p><div class="label-anchor"><span>eq: 5 »</span></div> \[\tilde{I}(x,t)=I(x,t)+\alpha B(x,t)\]</p>
<p>联立公式 2～4 ，可以得到</p>
<p><div class="label-anchor"><span>eq: 6 »</span></div> \[ \tilde{I}(x,t)\approx f(x)+\color{red}{(1+\alpha)}\color{blue}{\delta(t)\frac{\partial f(x)}{\partial x}} \]</p>
<p>在这种理想情况下，这个 \(\tilde{I}(x,t)\) 约等于我们希望得到的 \(I(x,t)\) ，即：</p>
<p><div class="label-anchor"><span>eq: 7 »</span></div> \[ \tilde{I}(x,t)\approx f(x+\color{red}{(1+\alpha)}\delta(t)) \]</p>
<p>下图演示了使用上面的方法将一个余弦波放大 \(\alpha\) 倍的过程和结果。其中，黑色的曲线表示原信号 \(f(x)\) ，蓝色的曲线表示变化后的信号 \(f(x+\delta)\) ，青色的曲线表示对这个信号的泰勒级数逼近 \(f(x)+\delta(t)\frac{\partial f(x)}{\partial x}\)，绿色的曲线表示我们分离出来的变化的部分。我们将这个部分放大 \(\alpha\) 倍再加回原信号就得到放大后的信号，图中红色的曲线表示这个放大后的信号 \(f(x)+(1+\alpha)B(x, t))\) 。</p>
<p><img src="/images/eulerian-video-magnification/19489Gf.png" alt="Temporal filtering can approximate spatial translation"></p>
<h4 id="非理想情况">非理想情况</h4>
<p>不过，有些时候，我们并没有那么幸运——变化信号 \(\delta(t)\) 的频率范围超出了我们所选的频段范围。这种情况下，应用带通滤波意味着只是保留了一部分的变化信号，而其他频率超出范围的信号将会被减弱。因此，我们用 \(\gamma_k(t)\) 来表示在 \(t\) 时刻变化第 \(k\) 个变化信号减弱的倍数（\(0\le \gamma_k \le 1\)）<span class="margin-note-marker"><sup>3</sup></span> <span class="block margin-div-outer"><span class="block margin-div-inner"><span class="block margin-note"><span class="margin-note-marker">3</span>它的值和所选的带通滤波器有关。实际上论文原作者考虑这个情况仅仅是出于论证上的严密，在实现时我们不需要计算它，只需要得到 B(x,t) ，而这个值是上一步的带通结果。 </span></span></span>，则有：</p>
<p><div class="label-anchor"><span>eq: 8 »</span></div> \[B(x,t) = \sum_k \gamma_{k}\delta_{k}(t)\frac{\partial f(x)}{\partial x}\]</p>
<p>之后我们又要对它乘以放大倍数 \(\alpha\) 。既然两步都是乘以一个倍数，为了方便起见，我们干脆把这两个线性变化合为一步，即让放大倍数 \(\alpha_k = \gamma_{k}\alpha\) ，则：</p>
<p><div class="label-anchor"><span>eq: 9 »</span></div> \[\tilde {I}(x,t)\approx f(x+\sum_k(1+\alpha_{k})\delta_{k}(t))\]</p>
<h3 id="放大倍数限制">放大倍数限制</h3>
<p>线性的 EVM 方法会在放大动作变化的同时放大噪声，为了避免造成太大的失真，可以设置一个合理的放大倍数限制。假定信号的空间波长为 \(\lambda = \frac{2\pi}{\omega}\) ，这个限制可以用公式 9 来表示：</p>
<p><div class="label-anchor"><span>eq: 10 »</span></div> \[(1+\alpha)\delta(t) \lt \frac{\lambda}{8}\]</p>
<p>当超出这个边界的时候，我们可以让 \(\alpha\) 维持在一个边界值，如下图所示：</p>
<p><img src="/images/eulerian-video-magnification/1948KRl.png" alt="Bounds of amplification factor"></p>
<p>不过，如果要放大的是颜色的变化，那么从视觉上看并不会很受影响（或者说这种颜色的失真就是我们想要的），这时候就可以不用对 \(\alpha\) 进行限制，或者使用一个更小的空间波长下限值。</p>
<h2 id="算法实现">算法实现</h2>
<p>这一节将介绍我使用 OpenCV 实现线性欧拉影像放大算法的心得。</p>
<p><div class="alert alert-warning"><i class="fa fa-bell"></i>  <ul>
<li>本文的源码遵守 LGPL v3 协议，但这个技术已由原作者申请了专利，因此请勿直接用于商业用途。</li>
<li>动作放大的模块引用了 Yusuke Tomoto 的 <a href="https://github.com/yusuketomoto/ofxEvm" target="_blank" rel="external">ofxEvm</a> 项目的相关代码。这个项目基于 EVM 实现了对动作的放大。对于初学者，我建议先阅读他的代码。</li>
<li>另外特别感谢 <a href="http://web.mit.edu/dron/www/portfolio/" target="_blank" rel="external">Daniel Ron</a> 和 <a href="https://github.com/alessandro-gentilini" target="_blank" rel="external">Aalessandro Gentilini</a> 的大力援助，没有他们我无法完成这个程序。</li>
</ul>
</div></p>
<h3 id="颜色空间转换">颜色空间转换</h3>
<p>颜色空间转换在原论文中只是一笔带过，但这一步对于放大动作还是非常有用的。在进入整个 framework 之前，作者建议先将图像的颜色空间由 RGB 转换到 <a href="http://en.wikipedia.org/wiki/YIQ" target="_blank" rel="external">YIQ</a> 。YIQ 是 NTSC 电视机系统所采用的颜色空间，<strong>Y</strong> 是提供黑白电视及彩色电视的亮度信号，<strong>I</strong> 代表 In-phase，色彩从橙色到青色，<strong>Q</strong> 代表 Quadrature-phase，色彩从紫色到黄绿色。</p>
<p>采用这种颜色空间可以方便在后期使用一个衰减因子来减少噪声：对于只想放大动作变化的情况，颜色就应该不会发生太大变化，所以我们可以用这个衰减因子来减小放大后的信号的 I 和 Q 两个分量的值。然后再转回 RGB 颜色空间<span class="margin-note-marker"><sup>4</sup></span> <span class="block margin-div-outer"><span class="block margin-div-inner"><span class="block margin-note"><span class="margin-note-marker">4</span>类似的颜色空间还有 Lab，经过我的测试，使用 Lab 颜色空间也有效。 </span></span></span>。两个转换函数实现如下：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">void</span> rgb2ntsc(<span class="keyword">const</span> Mat_&lt;Vec3f&gt;& src, Mat_&lt;Vec3f&gt;& dst)</div><div class="line">{</div><div class="line">    Mat ret = src.clone();</div><div class="line">    Mat T = (Mat_&lt;<span class="keyword">float</span>&gt;(<span class="number">3</span>,<span class="number">3</span>) &lt;&lt; <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0.956</span>, -<span class="number">0.272</span>, -<span class="number">1.106</span>, <span class="number">0.621</span>, -<span class="number">0.647</span>, <span class="number">1.703</span>);</div><div class="line">    T = T.inv(); <span class="comment">//here inverse!</span></div><div class="line">    </div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;src.rows; j++) {</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;src.cols; i++) {</div><div class="line">            ret.at&lt;Vec3f&gt;(j,i)(<span class="number">0</span>) = src.at&lt;Vec3f&gt;(j,i)(<span class="number">0</span>) * T.at&lt;<span class="keyword">float</span>&gt;(<span class="number">0.0</span>)</div><div class="line">            + src.at&lt;Vec3f&gt;(j,i)(<span class="number">1</span>) * T.at&lt;<span class="keyword">float</span>&gt;(<span class="number">0</span>,<span class="number">1</span>)</div><div class="line">            + src.at&lt;Vec3f&gt;(j,i)(<span class="number">2</span>) * T.at&lt;<span class="keyword">float</span>&gt;(<span class="number">0</span>,<span class="number">2</span>);</div><div class="line">            </div><div class="line">            ret.at&lt;Vec3f&gt;(j,i)(<span class="number">1</span>) = src.at&lt;Vec3f&gt;(j,i)(<span class="number">0</span>) * T.at&lt;<span class="keyword">float</span>&gt;(<span class="number">1.0</span>)</div><div class="line">            + src.at&lt;Vec3f&gt;(j,i)(<span class="number">1</span>) * T.at&lt;<span class="keyword">float</span>&gt;(<span class="number">1</span>,<span class="number">1</span>)</div><div class="line">            + src.at&lt;Vec3f&gt;(j,i)(<span class="number">2</span>) * T.at&lt;<span class="keyword">float</span>&gt;(<span class="number">1</span>,<span class="number">2</span>);</div><div class="line">            </div><div class="line">            ret.at&lt;Vec3f&gt;(j,i)(<span class="number">2</span>) = src.at&lt;Vec3f&gt;(j,i)(<span class="number">0</span>) * T.at&lt;<span class="keyword">float</span>&gt;(<span class="number">2.0</span>)</div><div class="line">            + src.at&lt;Vec3f&gt;(j,i)(<span class="number">1</span>) * T.at&lt;<span class="keyword">float</span>&gt;(<span class="number">2</span>,<span class="number">1</span>)</div><div class="line">            + src.at&lt;Vec3f&gt;(j,i)(<span class="number">2</span>) * T.at&lt;<span class="keyword">float</span>&gt;(<span class="number">2</span>,<span class="number">2</span>);</div><div class="line">        }</div><div class="line">    }</div><div class="line">    dst = ret;</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keyword">void</span> ntsc2rgb(<span class="keyword">const</span> Mat_&lt;Vec3f&gt;& src, Mat_&lt;Vec3f&gt;& dst)</div><div class="line">{</div><div class="line">    Mat ret = src.clone();</div><div class="line">    Mat T = (Mat_&lt;<span class="keyword">float</span>&gt;(<span class="number">3</span>,<span class="number">3</span>) &lt;&lt; <span class="number">1.0</span>, <span class="number">0.956</span>, <span class="number">0.621</span>, <span class="number">1.0</span>, -<span class="number">0.272</span>, -<span class="number">0.647</span>, <span class="number">1.0</span>, -<span class="number">1.106</span>, <span class="number">1.703</span>);</div><div class="line">    T = T.t(); <span class="comment">//here transpose!</span></div><div class="line">    </div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;src.rows; j++) {</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;src.cols; i++) {</div><div class="line">            ret.at&lt;Vec3f&gt;(j,i)(<span class="number">0</span>) = src.at&lt;Vec3f&gt;(j,i)(<span class="number">0</span>) * T.at&lt;<span class="keyword">float</span>&gt;(<span class="number">0.0</span>)</div><div class="line">            + src.at&lt;Vec3f&gt;(j,i)(<span class="number">1</span>) * T.at&lt;<span class="keyword">float</span>&gt;(<span class="number">0</span>,<span class="number">1</span>)</div><div class="line">            + src.at&lt;Vec3f&gt;(j,i)(<span class="number">2</span>) * T.at&lt;<span class="keyword">float</span>&gt;(<span class="number">0</span>,<span class="number">2</span>);</div><div class="line">            </div><div class="line">            ret.at&lt;Vec3f&gt;(j,i)(<span class="number">1</span>) = src.at&lt;Vec3f&gt;(j,i)(<span class="number">0</span>) * T.at&lt;<span class="keyword">float</span>&gt;(<span class="number">1.0</span>)</div><div class="line">            + src.at&lt;Vec3f&gt;(j,i)(<span class="number">1</span>) * T.at&lt;<span class="keyword">float</span>&gt;(<span class="number">1</span>,<span class="number">1</span>)</div><div class="line">            + src.at&lt;Vec3f&gt;(j,i)(<span class="number">2</span>) * T.at&lt;<span class="keyword">float</span>&gt;(<span class="number">1</span>,<span class="number">2</span>);</div><div class="line">            </div><div class="line">            ret.at&lt;Vec3f&gt;(j,i)(<span class="number">2</span>) = src.at&lt;Vec3f&gt;(j,i)(<span class="number">0</span>) * T.at&lt;<span class="keyword">float</span>&gt;(<span class="number">2.0</span>)</div><div class="line">            + src.at&lt;Vec3f&gt;(j,i)(<span class="number">1</span>) * T.at&lt;<span class="keyword">float</span>&gt;(<span class="number">2</span>,<span class="number">1</span>)</div><div class="line">            + src.at&lt;Vec3f&gt;(j,i)(<span class="number">2</span>) * T.at&lt;<span class="keyword">float</span>&gt;(<span class="number">2</span>,<span class="number">2</span>);</div><div class="line">        }</div><div class="line">    }</div><div class="line">    dst = ret;</div><div class="line">}</div></pre></td></tr></table></figure></p>
<h3 id="空间滤波-v2">空间滤波</h3>
<p>如前面所述，EVM 算法可以使用拉普拉斯金字塔和高斯金字塔来进行空间滤波。使用哪个金字塔得根据具体需求而定。如果要放大的是动作的变化，那么可以选择拉普拉斯金字塔，构造多个不同空间频率的基带；如果要放大的是颜色的变化，不同基带的 SNR 应该比较接近，因此可以选择高斯金字塔，只取最顶层下采样和低通滤波的结果。这两个金字塔可以很容易地利用 OpenCV 的 <code>cv::PyDown()</code> 和 <code>cv::PyUp()</code> 两个函数来构造：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/** </span></div><div class="line"> * buildLaplacianPyramid	-	construct a laplacian pyramid from given image</div><div class="line"> *</div><div class="line"> * @param img		-	source image</div><div class="line"> * @param levels	-	levels of the destinate pyramids</div><div class="line"> * @param pyramid	-	destinate image</div><div class="line"> *</div><div class="line"> * @return true if success</div><div class="line"> */</div><div class="line"><span class="keyword">bool</span> buildLaplacianPyramid(<span class="keyword">const</span> cv::Mat &img, <span class="keyword">const</span> <span class="keyword">int</span> levels,</div><div class="line">                           std::<span class="stl_container"><span class="built_in">vector</span>&lt;cv::Mat_&lt;cv::Vec3f&gt;</span> &gt; &pyramid)</div><div class="line">{</div><div class="line">    <span class="keyword">if</span> (levels &lt; <span class="number">1</span>){</div><div class="line">        perror(<span class="string">"Levels should be larger than 1"</span>);</div><div class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">    }</div><div class="line">    pyramid.clear();</div><div class="line">    cv::Mat currentImg = img;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> l=<span class="number">0</span>; l&lt;levels; l++) {</div><div class="line">        cv::Mat down,up;</div><div class="line">        pyrDown(currentImg, down);</div><div class="line">        pyrUp(down, up, currentImg.size());</div><div class="line">        cv::Mat lap = currentImg - up;</div><div class="line">        pyramid.push_back(lap);</div><div class="line">        currentImg = down;</div><div class="line">    }</div><div class="line">    pyramid.push_back(currentImg);</div><div class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">}</div><div class="line"></div><div class="line"><span class="comment">/** </span></div><div class="line"> * buildGaussianPyramid	-	construct a gaussian pyramid from a given image</div><div class="line"> *</div><div class="line"> * @param img		-	source image</div><div class="line"> * @param levels	-	levels of the destinate pyramids</div><div class="line"> * @param pyramid	-	destinate image</div><div class="line"> *</div><div class="line"> * @return true if success</div><div class="line"> */</div><div class="line"><span class="keyword">bool</span> buildGaussianPyramid(<span class="keyword">const</span> cv::Mat &img,</div><div class="line">                          <span class="keyword">const</span> <span class="keyword">int</span> levels,</div><div class="line">                          std::<span class="stl_container"><span class="built_in">vector</span>&lt;cv::Mat_&lt;cv::Vec3f&gt;</span> &gt; &pyramid)</div><div class="line">{</div><div class="line">    <span class="keyword">if</span> (levels &lt; <span class="number">1</span>){</div><div class="line">        perror(<span class="string">"Levels should be larger than 1"</span>);</div><div class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">    }</div><div class="line">    pyramid.clear();</div><div class="line">    cv::Mat currentImg = img;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> l=<span class="number">0</span>; l&lt;levels; l++) {</div><div class="line">        cv::Mat down;</div><div class="line">        cv::pyrDown(currentImg, down);        </div><div class="line">        pyramid.push_back(down);</div><div class="line">        currentImg = down;</div><div class="line">    }</div><div class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">}</div></pre></td></tr></table></figure></p>
<h3 id="时域滤波-v2">时域滤波</h3>
<p>同样，时域滤波可以根据不同的需求选择不同的带通滤波器。如果需要对放大结果进行后续的时频分析，则可以选择理想带通滤波器；如果不需要对放大结果进行时频分析，可以选择宽通带的滤波器，如 Butterworth 带通滤波器，二级IIR 滤波器等。这里分别实现了二阶 IIR 带通滤波器和理想带通滤波器：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/** </span></div><div class="line"> * temporalIIRFilter	-	temporal IIR filtering an image</div><div class="line"> *                          (thanks to Yusuke Tomoto)</div><div class="line"> * @param pyramid	-	source image</div><div class="line"> * @param filtered	-	filtered result</div><div class="line"> *</div><div class="line"> */</div><div class="line"><span class="keyword">void</span> VideoProcessor::temporalIIRFilter(<span class="keyword">const</span> cv::Mat &src,</div><div class="line">                                    cv::Mat &dst)</div><div class="line">{</div><div class="line">    cv::Mat temp1 = (<span class="number">1</span>-fh)*lowpass1[curLevel] + fh*src;</div><div class="line">    cv::Mat temp2 = (<span class="number">1</span>-fl)*lowpass2[curLevel] + fl*src;</div><div class="line">    lowpass1[curLevel] = temp1;</div><div class="line">    lowpass2[curLevel] = temp2;</div><div class="line">    dst = lowpass1[curLevel] - lowpass2[curLevel];</div><div class="line">}</div><div class="line"></div><div class="line"><span class="comment">/** </span></div><div class="line"> * temporalIdalFilter	-	temporal IIR filtering an image pyramid of concat-frames</div><div class="line"> *                          (Thanks to Daniel Ron & Alessandro Gentilini)</div><div class="line"> *</div><div class="line"> * @param pyramid	-	source pyramid of concatenate frames</div><div class="line"> * @param filtered	-	concatenate filtered result</div><div class="line"> *</div><div class="line"> */</div><div class="line"><span class="keyword">void</span> VideoProcessor::temporalIdealFilter(<span class="keyword">const</span> cv::Mat &src,</div><div class="line">                                          cv::Mat &dst)</div><div class="line">{</div><div class="line">    cv::Mat channels[<span class="number">3</span>];</div><div class="line"></div><div class="line">    <span class="comment">// split into 3 channels</span></div><div class="line">    cv::split(src, channels);</div><div class="line"></div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">3</span>; ++i){</div><div class="line"></div><div class="line">        cv::Mat current = channels[i];  <span class="comment">// current channel</span></div><div class="line">        cv::Mat tempImg;</div><div class="line"></div><div class="line">        <span class="keyword">int</span> width = cv::getOptimalDFTSize(current.cols);</div><div class="line">        <span class="keyword">int</span> height = cv::getOptimalDFTSize(current.rows);</div><div class="line"></div><div class="line">        cv::copyMakeBorder(current, tempImg,</div><div class="line">                           <span class="number">0</span>, height - current.rows,</div><div class="line">                           <span class="number">0</span>, width - current.cols,</div><div class="line">                           cv::BORDER_CONSTANT, cv::Scalar::all(<span class="number">0</span>));</div><div class="line"></div><div class="line">        <span class="comment">// do the DFT</span></div><div class="line">        cv::dft(tempImg, tempImg, cv::DFT_ROWS | cv::DFT_SCALE, tempImg.rows);</div><div class="line"></div><div class="line">        <span class="comment">// construct the filter</span></div><div class="line">        cv::Mat filter = tempImg.clone();</div><div class="line">        createIdealBandpassFilter(filter, fl, fh, rate);</div><div class="line"></div><div class="line">        <span class="comment">// apply filter</span></div><div class="line">        cv::mulSpectrums(tempImg, filter, tempImg, cv::DFT_ROWS);</div><div class="line"></div><div class="line">        <span class="comment">// do the inverse DFT on filtered image</span></div><div class="line">        cv::idft(tempImg, tempImg, cv::DFT_ROWS | cv::DFT_SCALE, tempImg.rows);</div><div class="line"></div><div class="line">        <span class="comment">// copy back to the current channel</span></div><div class="line">        tempImg(cv::Rect(<span class="number">0</span>, <span class="number">0</span>, current.cols, current.rows)).copyTo(channels[i]);</div><div class="line">    }</div><div class="line">    <span class="comment">// merge channels</span></div><div class="line">    cv::merge(channels, <span class="number">3</span>, dst);</div><div class="line"></div><div class="line">    <span class="comment">// normalize the filtered image</span></div><div class="line">    cv::normalize(dst, dst, <span class="number">0</span>, <span class="number">1</span>, CV_MINMAX);</div><div class="line">}</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * createIdealBandpassFilter	-	create a 1D ideal band-pass filter</div><div class="line"> *</div><div class="line"> * @param filter    -	destinate filter</div><div class="line"> * @param fl        -	low cut-off</div><div class="line"> * @param fh		-	high cut-off</div><div class="line"> * @param rate      -   sampling rate(i.e. video frame rate)</div><div class="line"> */</div><div class="line"><span class="keyword">void</span> VideoProcessor::createIdealBandpassFilter(cv::Mat &filter, <span class="keyword">double</span> fl, <span class="keyword">double</span> fh, <span class="keyword">double</span> rate)</div><div class="line">{</div><div class="line">    <span class="keyword">int</span> width = filter.cols;</div><div class="line">    <span class="keyword">int</span> height = filter.rows;</div><div class="line"></div><div class="line">    fl = <span class="number">2</span> * fl * width / rate;</div><div class="line">    fh = <span class="number">2</span> * fh * width / rate;</div><div class="line"></div><div class="line">    <span class="keyword">double</span> response;</div><div class="line"></div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; height; ++i) {</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; width; ++j) {</div><div class="line">            <span class="comment">// filter response</span></div><div class="line">            <span class="keyword">if</span> (j &gt;= fl && j &lt;= fh)</div><div class="line">                response = <span class="number">1.0f</span>;</div><div class="line">            <span class="keyword">else</span></div><div class="line">                response = <span class="number">0.0f</span>;</div><div class="line">            filter.at&lt;<span class="keyword">float</span>&gt;(i, j) = response;</div><div class="line">        }</div><div class="line">    }</div><div class="line">}</div></pre></td></tr></table></figure></p>
<h3 id="放大变化">放大变化</h3>
<p>根据前面的公式 5 和公式 8，可以设计如下的放大函数：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/** </span></div><div class="line"> * amplify	-	ampilfy the motion</div><div class="line"> *</div><div class="line"> * @param filtered	- motion image</div><div class="line"> */</div><div class="line"><span class="keyword">void</span> VideoProcessor::amplify(<span class="keyword">const</span> cv::Mat &src, cv::Mat &dst)</div><div class="line">{</div><div class="line">    <span class="keyword">float</span> curAlpha;    </div><div class="line">    <span class="keyword">switch</span> (spatialType) {</div><div class="line">    <span class="keyword">case</span> LAPLACIAN:        <span class="comment">// for motion magnification</span></div><div class="line">        <span class="comment">//compute modified alpha for this level</span></div><div class="line">        curAlpha = lambda/delta/<span class="number">8</span> - <span class="number">1</span>;</div><div class="line">        curAlpha *= exaggeration_factor;</div><div class="line">        <span class="keyword">if</span> (curLevel==levels || curLevel==<span class="number">0</span>)     <span class="comment">// ignore the highest and lowest frequency band</span></div><div class="line">            dst = src * <span class="number">0</span>;</div><div class="line">        <span class="keyword">else</span></div><div class="line">            dst = src * cv::min(alpha, curAlpha);</div><div class="line">        <span class="keyword">break</span>;</div><div class="line">    <span class="keyword">case</span> GAUSSIAN:        <span class="comment">// for color magnification</span></div><div class="line">        dst = src * alpha;</div><div class="line">        <span class="keyword">break</span>;</div><div class="line">    <span class="keyword">default</span>:</div><div class="line">        <span class="keyword">break</span>;</div><div class="line">    }</div><div class="line">}</div></pre></td></tr></table></figure></p>
<p>对于动作信号的放大，调用这个函数前需要先算出每一层基带的 \(\lambda\) 以及 \(\delta(t)\) 的值，以便于根据公式 10 来计算当前合理的放大倍数：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">delta = lambda_c/<span class="number">8.0</span>/(<span class="number">1.0</span>+alpha);</div><div class="line"><span class="comment">// the factor to boost alpha above the bound</span></div><div class="line"><span class="comment">// (for better visualization)</span></div><div class="line">exaggeration_factor = <span class="number">2.0</span>;</div><div class="line"></div><div class="line"><span class="comment">// compute the representative wavelength lambda</span></div><div class="line"><span class="comment">// for the lowest spatial frequency band of Laplacian pyramid</span></div><div class="line">lambda = <span class="built_in">sqrt</span>(w*w + h*h)/<span class="number">3</span>;  <span class="comment">// 3 is experimental constant</span></div></pre></td></tr></table></figure></p>
<p>注意：这里的 \(\lambda_c\) 就是前面所提的空间波长的下限值。对于 \(\lambda &lt; \lambda_c\) 的基带，\(\alpha\) 值将被减弱。另外，还加了一个 <code>exaggeration_factor</code> 参数，它是一个魔数（magic number），用来将符合 \(\lambda > \lambda_c\) 的基带加倍放大。</p>
<h3 id="合成图像">合成图像</h3>
<p>先合成变化信号的图像，再与原图进行叠加。根据使用金字塔的类型，编写对应的合成方法：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/** </span></div><div class="line"> * reconImgFromLaplacianPyramid	-	reconstruct image from given laplacian pyramid</div><div class="line"> *</div><div class="line"> * @param pyramid	-	source laplacian pyramid</div><div class="line"> * @param levels	-	levels of the pyramid</div><div class="line"> * @param dst		-	destinate image</div><div class="line"> */</div><div class="line"><span class="keyword">void</span> reconImgFromLaplacianPyramid(<span class="keyword">const</span> std::<span class="stl_container"><span class="built_in">vector</span>&lt;cv::Mat_&lt;cv::Vec3f&gt;</span> &gt; &pyramid,</div><div class="line">                                  <span class="keyword">const</span> <span class="keyword">int</span> levels,</div><div class="line">                                  cv::Mat_&lt;cv::Vec3f&gt; &dst)</div><div class="line">{</div><div class="line">    cv::Mat currentImg = pyramid[levels];</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> l=levels-<span class="number">1</span>; l&gt;=<span class="number">0</span>; l--) {</div><div class="line">        cv::Mat up;</div><div class="line">        cv::pyrUp(currentImg, up, pyramid[l].size());</div><div class="line">        currentImg = up + pyramid[l];</div><div class="line">    }</div><div class="line">    dst = currentImg.clone();</div><div class="line">}</div><div class="line"></div><div class="line"><span class="comment">/** </span></div><div class="line"> * upsamplingFromGaussianPyramid	-	up-sampling an image from gaussian pyramid</div><div class="line"> *</div><div class="line"> * @param src		-	source image</div><div class="line"> * @param levels	-	levels of the pyramid</div><div class="line"> * @param dst		-	destinate image</div><div class="line"> */</div><div class="line"><span class="keyword">void</span> upsamplingFromGaussianPyramid(<span class="keyword">const</span> cv::Mat &src,</div><div class="line">                                   <span class="keyword">const</span> <span class="keyword">int</span> levels,</div><div class="line">                                   cv::Mat_&lt;cv::Vec3f&gt; &dst)</div><div class="line">{</div><div class="line">    cv::Mat currentLevel = src.clone();</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; levels; ++i) {</div><div class="line">        cv::Mat up;</div><div class="line">        cv::pyrUp(currentLevel, up);</div><div class="line">        currentLevel = up;</div><div class="line">    }</div><div class="line">    currentLevel.copyTo(dst);</div><div class="line">}</div></pre></td></tr></table></figure></p>
<h3 id="衰减-i-q-通道">衰减 I、Q 通道</h3>
<p>对于动作信号的放大，可以在后期引入一个衰减因子减弱 I、Q 两个通道的变化幅度，最后才转回 RGB 颜色空间。</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/** </span></div><div class="line"> * attenuate	-	attenuate I, Q channels</div><div class="line"> *</div><div class="line"> * @param src	-	source image</div><div class="line"> * @param dst   -   destinate image</div><div class="line"> */</div><div class="line"><span class="keyword">void</span> VideoProcessor::attenuate(cv::Mat &src, cv::Mat &dst)</div><div class="line">{</div><div class="line">    cv::Mat planes[<span class="number">3</span>];</div><div class="line">    cv::split(src, planes);</div><div class="line">    planes[<span class="number">1</span>] = planes[<span class="number">1</span>] * chromAttenuation;</div><div class="line">    planes[<span class="number">2</span>] = planes[<span class="number">2</span>] * chromAttenuation;</div><div class="line">    cv::merge(planes, <span class="number">3</span>, dst);</div><div class="line">}</div></pre></td></tr></table></figure></p>
<h2 id="结果">结果</h2>
<p>下面演示使用我的程序，对论文提供的 face 案例进行处理的结果。</p>
<p>所选参数如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>\(\alpha\)</th>
<th>\(\lambda_c\)</th>
<th>频段</th>
<th>衰减因子</th>
</tr>
</thead>
<tbody>
<tr>
<td>动作变化放大</td>
<td>10</td>
<td>80</td>
<td>0.05~0.4</td>
<td>0.1</td>
</tr>
<tr>
<td>颜色变化放大</td>
<td>50</td>
<td>-</td>
<td>0.83~1.0</td>
<td>-</td>
</tr>
</tbody>
</table>
<h3 id="原视频">原视频</h3>
<p><embed src="http://player.youku.com/player.php/sid/XNjg4Nzc0NjI4/v.swf" allowfullscreen="true" quality="high" width="100%" height="400" align="middle" allowscriptaccess="always" type="application/x-shockwave-flash"></p>
<h3 id="动作变化放大结果">动作变化放大结果</h3>
<p><embed src="http://player.youku.com/player.php/sid/XNjkwNTk2MDAw/v.swf" allowfullscreen="true" quality="high" width="100%" height="400" align="middle" allowscriptaccess="always" type="application/x-shockwave-flash"></p>
<h3 id="颜色变化放大结果">颜色变化放大结果</h3>
<p><embed src="http://player.youku.com/player.php/sid/XNjg4Nzc1NTE2/v.swf" allowfullscreen="true" quality="high" width="100%" height="400" align="middle" allowscriptaccess="always" type="application/x-shockwave-flash"></p>
<h2 id="源码和程序">源码和程序</h2>
<ul>
<li>
<p><i class="fa fa-github"></i> <a href="https://github.com/wzpan/QtEVM" target="_blank"> QtEVM 的源码 </a></p>
</li>
<li>
<p><i class="fa fa-download"></i><a href="http://pan.baidu.com/s/1mgE2I1a" target="_blank"> QtEVM 的 Win32 可执行程序 </a></p>
</li>
</ul>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>Poh, M.-Z., McDuff, D.J. and Picard, R.W. 2010. Non-contact, automated cardiac pulse measurements using video imaging and blind source separation. (2010). <a href="#fnref1" class="footnote-backref">↩</a></p>
</li>
<li id="fn2" class="footnote-item"><p>Verkruysse, W., Svaasand, L.O. and Nelson, J.S. 2008. Remote plethysmographic imaging using ambient light. Optics express. 16, 26 (2008), 21434–21445. <a href="#fnref2" class="footnote-backref">↩</a></p>
</li>
<li id="fn3" class="footnote-item"><p>Liu, C., Torralba, A., Freeman, W.T., Durand, F. and Adelson, E.H. 2005. Motion magnification. ACM Transactions on Graphics (TOG) (2005), 519–526. <a href="#fnref3" class="footnote-backref">↩</a></p>
</li>
<li id="fn4" class="footnote-item"><p>Wu, H.-Y., Rubinstein, M., Shih, E., Guttag, J., Durand, F. and Freeman, W. 2012. Eulerian video magnification for revealing subtle changes in the world. ACM Transactions on Graphics (TOG). 31, 4 (2012), 65. <a href="#fnref4" class="footnote-backref">↩</a></p>
</li>
<li id="fn5" class="footnote-item"><p>Wadhwa, N., Rubinstein, M., Durand, F. and Freeman, W.T. 2013. Phase-Based Video Motion Processing. ACM Trans. Graph. (Proceedings SIGGRAPH 2013). 32, 4 (2013). <a href="#fnref5" class="footnote-backref">↩</a></p>
</li>
</ol>
</section>

		</div>

		<!-- jiathis -->
		
<!-- JiaThis Button BEGIN -->
<script type="text/javascript">
var jiathis_config = {data_track_clickback:'true'};
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jiathis_r.js?type=left&amp;move=0&amp;btn=l2.gif&amp;uid=1538060" charset="utf-8"></script>
<!-- JiaThis Button END -->

        

		<!-- pagination -->
		<div>
		<center>
		<div class="pagination">
	 
      <ul>
		
		<li class="prev"><a data-pjax href="/slides/learn-linux-programming-the-recursive-way/" class="alignleft prev"><i class="fa fa-arrow-circle-o-left"></i>Prev</a></li>
  		

		<li><a data-pjax href="/archive"><i class="fa fa-archive"></i>Archive</a></li>

        
			<li class="next"><a data-pjax href="/tools/wechat/" class="alignright next">Next<i class="fa fa-arrow-circle-o-right"></i></a></li>           
      </ul>
	
</div>

	        </center>
		</div>

        <!-- donate -->
        <!-- Donate Module -->
<div id="donate_module">
	<!-- css -->
	<style type="text/css">
		.donate_bar a.btn_donate{
			display: inline-block;
			width: 82px;
			height: 82px;
			background: url("http://img.t.sinajs.cn/t5/style/images/apps_PRF/e_media/btn_reward.gif") no-repeat;
			_background: url("http://img.t.sinajs.cn/t5/style/images/apps_PRF/e_media/btn_reward.gif") no-repeat;
			<!-- 因为本 hexo 生成的博客所用的 theme 的 a:hover 带动画效果，
				 为了在让打赏按钮显示效果正常 而 添加了以下几行 css，
				 嵌入其它博客时不一定要它们。 -->
			-webkit-transition: background 0s;
			-moz-transition: background 0s;
			-o-transition: background 0s;
			-ms-transition: background 0s;
			transition: background 0s;
			<!-- /让打赏按钮的效果显示正常 而 添加的几行 css 到此结束 -->
		}
		.donate_bar a.btn_donate:hover{ background-position: 0px -82px;}
		.donate_bar .donate_txt {
			display: block;
			color: #9d9d9d;
			font: 14px/2 "Microsoft Yahei";
		}
		.bold{ font-weight: bold; }
	</style>
	<!-- /css -->
	<!-- btn_donate & tips -->
	<div id="donate_board" class="donate_bar center">
		<a id="btn_donate" class="btn_donate" target="_self" href="javascript:;" title="Donate 打赏"></a>
	</div>
	<!-- /btn_donate & tips -->
	<!-- donate guide -->
	<div id="donate_guide" class="donate_bar center hidden">
        <div class="row center">
		<a href="http://7xj89i.com1.z0.glb.clouddn.com/ali_pay_01.jpg" title="Alipay_Scan_Payment" class="fancybox">
			<img src="http://7xj89i.com1.z0.glb.clouddn.com/ali_pay_01.jpg" title="Donate 打赏" height="164px" width="164px" style="display:inherit;"/>
		</a>&nbsp;
		<a href="http://7xj89i.com1.z0.glb.clouddn.com/wechat_pay_02.png" title="WeChat_Scan_Payment" class="fancybox">
			<img src="http://7xj89i.com1.z0.glb.clouddn.com/wechat_pay_02.png" title="Donate 打赏" height="164px" width="164px" style="display:inherit;"/>
		</a>
        </div>
		<span class="donate_txt">
			Use App <span class="bold"><a href="http://global.alipay.com/ospay/home.htm">Alipay</a> / <a href="http://www.wechat.com/en/">WeChat</a></span>
			to scan QRCode~ Thx for your support.<br/>
			用手机 <span class="bold"><a href="https://mobile.alipay.com/index.htm">支付宝钱包</a> / <a href="http://weixin.qq.com/">微信</a></span>，
			扫一扫即可~ 谢谢您的鼓励。<br/>
			<br/>
		</span>
		<br/>
	</div>
	<!-- /donate guide -->
	<!-- donate script -->
	<script type="text/javascript">
		document.getElementById('btn_donate').onclick = function(){
			$('#donate_board').addClass('hidden');
			$('#donate_guide').removeClass('hidden');
		}
		function donate_on_web(){
			$('#donate').submit();
		}
	</script>
	<!-- /donate script -->
</div>
<!-- /Donate Module -->


		<!-- toc -->
		
   	<script type="text/javascript">
		jQuery(document).ready(function() {
				
		   generatePostTOC('.mypage',  2 , 2 );
		
		});
	</script>




		<!-- comment -->
		
<section id="comment">
    <h2 class="title">Comments</h2>
	
	 <div id="github-comment"></div>
	 <div id="loading-comment"></div>
	 <script type="text/javascript">
	   getComments({
	           github_user: "wzpan",
	           github_repo: "wzpan.github.io",
			   github_token: "0149f166735197952343b9f58d5bdc649567a8e1",
			   no_comment: "暂时还没有留言呢，点击下面的按钮去留言吧！",
			   go_to_comment: "去留言",
			   no_issue: "no_issue",
			   page_title: "Eulerian Video Magnification",
			   issue_id: "undefined"
			   });
	 </script>
	
</section>



		
	</div> <!-- span9/span12 -->
	
		<div class="span3">

	<!-- donate -->
	<div class="meta-widget">
	<a href="#donate_module"><i class="fa fa-smile-o"></i> Donate this article</a>
	</div>

	<!-- date -->
	
	<div class="meta-widget">
	<i class="fa fa-clock-o"></i>
	Mar 21 2014 
	</div>
	

	<!-- categories -->
    
	<div class="meta-widget">
	<a data-pjax data-toggle="collapse" data-target="#categorys"><i class="fa fa-folder"></i></a>	
    <ul id="categorys" class="tag_box list-unstyled collapse in">
          
  <li>
    <li><a data-pjax href="/categories/codes/">codes<span>30</span></a></li>
  </li>

    </ul>
	</div>
	
	
  	<!-- tags -->
	
	<div class="meta-widget">
	<a data-pjax data-toggle="collapse" data-target="#tags"><i class="fa fa-tags"></i></a>		  
    <ul id="tags" class="tag_box list-unstyled collapse in">	  
	    
  <li><a data-pjax href="/tags/OpenCV/">OpenCV<span>3</span></a></li> <li><a data-pjax href="/tags/video/">video<span>6</span></a></li> <li><a data-pjax href="/tags/EVM/">EVM<span>2</span></a></li>

    </ul>
	</div>
		
	
    <hr>
</div><!-- span3 -->

	

</div><!-- row-fluid post-full -->

	</div>	
  </div>
  <div class="container-narrow">
  <footer> <p>
  &copy; 2017 Joseph Pan
  
      with help from <a href="http://zespia.tw/hexo/" target="_blank">Hexo</a> and 
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1254469760'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s95.cnzz.com/z_stat.php%3Fid%3D1254469760' type='text/javascript'%3E%3C/script%3E"));</script>
. 
    <small>
     <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/deed.zh"><img title="知识共享许可协议" style="border-width: 0px; vertical-align: middle; display: inline; " src="/images/license.png"></a>
    </small>
</p>
 </footer>
</div> <!-- container-narrow -->


<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/dist/jquery.imagesloaded.min.js"></script>


<script src="/dist/gallery.min.js"></script>
<script src="/dist/bootstrap.min.js"></script>
<script src="/dist/jquery.tableofcontents.min.js"></script>
<script src="/dist/tocgenerator.min.js"></script>
<script src="/dist/require.min.js"></script>
<script src="/dist/main.min.js"></script>


<script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>




<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v1/st.js','_st');

  _st('install','ney3Rb77vMaWT2KUKFyt');
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
        tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
        TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
        messageStyle: "none"
    }); 
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


</body>
</html>
