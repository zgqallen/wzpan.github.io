<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>视频处理 | HaHack</title>
  <meta name="author" content="Joseph Pan">
  
  <meta name="description" content="参考资料：

《OpenCV 2 Computer Vision Application Programming Cookbook》
《The OpenCV Reference Manual》


读取视频
使用 CV::VideoCapture 来读取视频序列。
12345678910111213">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="视频处理"/>
  <meta property="og:site_name" content="HaHack"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/images/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="HaHack" type="application/atom+xml">
  
  <link rel="stylesheet" href="/dist/bootstrap.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/dist/bootstrap-responsive.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/dist/font-awesome.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/dist/style.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/dist/highlight.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/dist/sidenav.min.css" media="screen" type="text/css">  
  <link rel="stylesheet" href="/dist/responsive.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/dist/bubble.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/dist/google-fonts.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/dist/nprogress.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/dist/timeline-comment.min.css" media="screen" type="text/css">
  
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

<!--  -->
<!--     <link href='http://fonts.googleapis.com/css?family=PT+Sans+Narrow|PT+Sans:400,400italic,700,700italic|Droid+Serif:400,400italic' rel='stylesheet' type='text/css'> -->
<!--     <link href='http://fonts.googleapis.com/css?family=Roboto' rel='stylesheet' type='text/css'> -->
<!--  -->
  
<script src="/dist/jquery-2.0.3.min.js"></script>


    <script src="/dist/videoGFW.min.js"></script>
	
	


    <script src="/dist/github-comment.js"></script>
    <script src="/dist/markdown.min.js"></script>
    <script src="/dist/timeago.min.js"></script>
	<script src="/dist/spin.min.js"></script>


</head>


<body data-spy="scroll" data-target=".toc">  
  <header id="header" class="inner"><div class="navbar navbar-inverse navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container">
            <a data-pjax class="brand" href="/">HaHack</a>
            <button type="button" class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <div class="nav-collapse collapse">
            <ul class="nav">				
			    
				   <li><a data-pjax href="/archive" title="所有文章归档"><i class="fa fa-archive"></i>Archive</a></li>				   			    			
				   <li><a data-pjax href="/categories" title="所有文章分类"><i class="fa fa-folder"></i>Categories</a></li>				   			    			
				   <li><a data-pjax href="/tags" title="所有文章标签"><i class="fa fa-tags"></i>Tags</a></li>				   			    			
				
				<li class="divider-vertical"></li>
			   	<li><a data-pjax href="/wiki" title="我的笔记库"><i class="fa fa-tasks"></i>wiki</a></li>				   
				
            </ul>			
			<ul class="nav navright">
				<li class="dropdown">
				<a data-pjax href="#" title="订阅本站" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-rss"></i>Subscribe <b class="caret"></b></a>
                                <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
				
				   <li role="presentation"><a role="menuitem" tabindex="-1" href="/atom.xml" title="使用 RSS 阅读器订阅 HaHack"><i class="fa fa-rss-square"></i>RSS</a></li>
				
				   <li role="presentation"><a role="menuitem" tabindex="-1" href="/wechat.html" title="订阅 HaHack 的公众平台"><i class="fa fa-qrcode"></i>WeChat</a></li>
				
				   <li role="presentation"><a role="menuitem" tabindex="-1" href="http://toutiao.io/u/147640" title=""><i class="fa fa-align-justify"></i>Toutiao</a></li>
				
                	        </ul>
				</li>
				
				<li><a data-pjax href="/about" title="关于我"><i class="fa fa-user"></i>About</a></li>				   				
   					  
            </ul>
            </div> <!-- nav-collapse collapse -->
        </div> <!-- container -->
     </div> <!-- navbar-inner -->
</div> <!-- navbar navbar-inverse -->
</header>
  <div class="container" id="container">
  	<div class="content">
    	 

	
		<div class="page-header">		
			<h1> 视频处理</h1>
		</div>    
	



<div class="row-fluid wiki">
	<!-- span -->
    
        <div class="span3 toc"></div>
        <div class="span9 note">
    

	

		<!-- content -->
		<p><div class="alert alert-success"><i class="fa fa-lightbulb-o"></i>  <p>参考资料：</p>
<ul>
<li>《OpenCV 2 Computer Vision Application Programming Cookbook》</li>
<li>《The OpenCV Reference Manual》</li>
</ul>
</div></p>
<h2 id="读取视频">读取视频</h2>
<p>使用 <a href="http://docs.opencv.org/modules/highgui/doc/reading_and_writing_images_and_video.html#videocapture" target="_blank" rel="external"><code>CV::VideoCapture</code></a> 来读取视频序列。</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="preprocessor">#<span class="keyword">include</span> &lt;stdio.h&gt;</span></div><div class="line"><span class="preprocessor">#<span class="keyword">include</span> &lt;string&gt;</span></div><div class="line"><span class="preprocessor">#<span class="keyword">include</span> &lt;opencv2/imgproc/imgproc.hpp&gt;</span></div><div class="line"><span class="preprocessor">#<span class="keyword">include</span> &lt;opencv2/core/core.hpp&gt;</span></div><div class="line"><span class="preprocessor">#<span class="keyword">include</span> &lt;opencv2/highgui/highgui.hpp&gt;</span></div><div class="line"></div><div class="line"><span class="keyword">int</span> main()</div><div class="line">{</div><div class="line">    <span class="comment">// Open the video file</span></div><div class="line">    cv::VideoCapture capture(<span class="string">"../stomp.avi"</span>);</div><div class="line">    <span class="comment">// check if video successfully opened</span></div><div class="line">    <span class="keyword">if</span> (!capture.isOpened())</div><div class="line">        <span class="keyword">return</span> <span class="number">1</span>;</div><div class="line">    <span class="comment">// Get the frame rate</span></div><div class="line">    <span class="keyword">double</span> rate = capture.get(CV_CAP_PROP_FPS);</div><div class="line"></div><div class="line">    <span class="keyword">bool</span> stop(<span class="keyword">false</span>);</div><div class="line">    cv::Mat frame;  <span class="comment">// current video frame</span></div><div class="line">    cv::namedWindow(<span class="string">"Extracted Frame"</span>);</div><div class="line">    <span class="comment">// Delay between each frame in ms</span></div><div class="line">    <span class="comment">// corresponds to video frame rate</span></div><div class="line">    <span class="keyword">int</span> delay = <span class="number">1000</span> / rate;</div><div class="line">    <span class="comment">// for all frames in video</span></div><div class="line">    <span class="keyword">while</span> (!stop){</div><div class="line">        <span class="comment">// read next frame if any</span></div><div class="line">        <span class="keyword">if</span> (!capture.read(frame))</div><div class="line">            <span class="keyword">break</span>;</div><div class="line">        cv::imshow(<span class="string">"Extracted Frame"</span>, frame);</div><div class="line">        <span class="comment">// introduce a delay</span></div><div class="line">        <span class="comment">// or press key to stop</span></div><div class="line">        <span class="keyword">if</span> (cv::waitKey(delay) &gt;= <span class="number">0</span>)</div><div class="line">            stop = <span class="keyword">true</span>;</div><div class="line">    }</div><div class="line">    <span class="comment">// Close the video file</span></div><div class="line">    <span class="comment">// Not required since called by destructor</span></div><div class="line">    capture.release();</div><div class="line">}</div></pre></td></tr></table></figure></p>
<p>也可以通过类似的方法读入摄像头捕捉的视频，要改动的地方仅仅是将上面的视频文件名改为摄像头的 ID，默认的摄像头 ID 为 0。</p>
<h2 id="写入视频">写入视频</h2>
<p>使用 <a href="http://docs.opencv.org/modules/highgui/doc/reading_and_writing_images_and_video.html#videowriter" target="_blank" rel="external"><code>CV::VideoWriter</code></a> 来写入视频。</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="preprocessor">#<span class="keyword">include</span> &lt;iostream&gt;</span></div><div class="line"><span class="preprocessor">#<span class="keyword">include</span> &lt;iomanip&gt;</span></div><div class="line"><span class="preprocessor">#<span class="keyword">include</span> &lt;sstream&gt;</span></div><div class="line"><span class="preprocessor">#<span class="keyword">include</span> &lt;string&gt;</span></div><div class="line"><span class="preprocessor">#<span class="keyword">include</span> &lt;vector&gt;</span></div><div class="line"><span class="preprocessor">#<span class="keyword">include</span> &lt;dbg.h&gt;</span></div><div class="line"><span class="preprocessor">#<span class="keyword">include</span> &lt;opencv2/core/core.hpp&gt;</span></div><div class="line"><span class="preprocessor">#<span class="keyword">include</span> &lt;opencv2/highgui/highgui.hpp&gt;</span></div><div class="line"></div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</div><div class="line"></div><div class="line"><span class="keyword">int</span> main()</div><div class="line">{</div><div class="line">    VideoCapture cap;</div><div class="line">    cap.open(<span class="number">0</span>);</div><div class="line">    namedWindow(<span class="string">"MyVideo"</span>, <span class="number">1</span>);</div><div class="line">    <span class="keyword">double</span> dWidth = cap.get(CV_CAP_PROP_FRAME_WIDTH);</div><div class="line">    <span class="keyword">double</span> dHeight = cap.get(CV_CAP_PROP_FRAME_HEIGHT);</div><div class="line">    Size frameSize(<span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(dWidth), <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(dHeight));</div><div class="line">    </div><div class="line">    VideoWriter oVideoWriter(<span class="string">"MyVideo.avi"</span>, CV_FOURCC(<span class="string">'P'</span>,<span class="string">'I'</span>,<span class="string">'M'</span>,<span class="string">'1'</span>), <span class="number">20</span>, frameSize, <span class="keyword">true</span>);	<span class="comment">// initialize the VideoWriter objetct</span></div><div class="line"></div><div class="line">    <span class="keyword">while</span> (<span class="number">1</span>) {</div><div class="line">        Mat frame;</div><div class="line">        <span class="keyword">bool</span> bSuccess = cap.read(frame);</div><div class="line">        <span class="keyword">if</span> (!bSuccess){ <span class="comment">// if not success, break loop</span></div><div class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="string">"ERROR: cannot read a frame from video file"</span> &lt;&lt; endl;</div><div class="line">            <span class="keyword">break</span>;</div><div class="line">        }</div><div class="line">        </div><div class="line">        oVideoWriter.write(frame);</div><div class="line">        imshow(<span class="string">"MyVideo"</span>, frame); <span class="comment">// show the frame in "MyVideo" window</span></div><div class="line"></div><div class="line">        <span class="keyword">if</span>(waitKey(<span class="number">10</span>) == <span class="number">27</span>) {<span class="comment">// wait for ESC key</span></div><div class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="string">"ESC key is pressed by user"</span> &lt;&lt; endl;</div><div class="line">            <span class="keyword">break</span>;</div><div class="line">        }</div><div class="line">    }</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">}</div></pre></td></tr></table></figure></p>
<h2 id="目标检测">目标检测</h2>
<h3 id="mean-shift-和-camshift">mean-shift 和 camshift</h3>
<h4 id="均值漂移-mean-shift">均值漂移（mean-shift）</h4>
<p>mean-shift 算法是一种在一组数据的密度分布中寻找局部极值的稳定 <sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> 的方法。若分布是连续的，处理过程就比较容易，这种情况下本质上只需要对数据的密度直方图应用爬山算法即可。然而，对于离散的数据集，这个问题在某种程度上是比较麻烦的。</p>
<p>mean-shift 算法的步骤如下：</p>
<ol>
<li>选择搜索窗口。</li>
<li>计算窗口（可能是带权重的）的重心。</li>
<li>将窗口的中心设置在计算出的重心处。</li>
<li>返回第 2 步，直到窗口的位置不再变化（通常会）。</li>
</ol>
<p>OpenCV 提供 <code>cv::meanshift()</code> 函数来进行 mean-shift 算法跟踪。</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> cv::meanShift(InputArray probImage, Rect& window, TermCriteria criteria)</div></pre></td></tr></table></figure></p>
<p>其中，</p>
<ul>
<li><code>probImage</code> - 图像直方图反投影后的结果；</li>
<li><code>window</code> - 初始的查找窗口，即要跟踪的区域；</li>
<li><code>criteria</code> - 迭代搜索算法的终止条件，主要由 mean-shift 移动的最大迭代次数和可视为窗口位置收敛的最小移动距离组成。</li>
<li>返回的是收敛时算法的迭代次数。</li>
</ul>
<p>对于第一个参数 <code>probImage</code> ，可以直接使用 <code>cv::calcBackProject()</code> 得到的结果。但《OpenCV 2 Computer Vision Application Programming Cookbook》建议先把图像转换到 HSV 颜色空间，然后使用 Hue 单通道的直方图的反投影变换结果作为 <code>probImage</code> ；</p>
<p>获取彩色图像的 Hue 通道的直方图算法实现如下：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Computes the 1D Hue histogram with a mask.</span></div><div class="line"><span class="comment">// BGR source image is converted to HSV</span></div><div class="line">cv::MatND getHueHistogram(<span class="keyword">const</span> cv::Mat &image,</div><div class="line">                             <span class="keyword">int</span> minSaturation = <span class="number">0</span>) {</div><div class="line"></div><div class="line">    cv::MatND hist;</div><div class="line"></div><div class="line">    <span class="comment">// Convert to HSV color space</span></div><div class="line">    cv::Mat hsv;</div><div class="line">    cv::cvtColor(image, hsv, CV_BGR2HSV);</div><div class="line"></div><div class="line">       <span class="comment">// Mask to be used (or not)</span></div><div class="line">       cv::Mat mask;</div><div class="line"></div><div class="line">       <span class="keyword">if</span> (minSaturation &gt; <span class="number">0</span>) {</div><div class="line">           <span class="comment">// Spliting the 3 channels into 3 images</span></div><div class="line">           std::<span class="stl_container"><span class="built_in">vector</span>&lt;cv::Mat&gt;</span> v;</div><div class="line">           cv::split(hsv, v);</div><div class="line">           <span class="comment">// Mask out the low saturated pixels</span></div><div class="line">           cv::threshold(v[<span class="number">1</span>], mask, minSaturation,</div><div class="line">                         <span class="number">255</span>, cv::THRESH_BINARY);</div><div class="line">       }</div><div class="line"></div><div class="line">    <span class="comment">// Prepare arguments for a 1D hue histogram</span></div><div class="line">    hranges[<span class="number">0</span>]= <span class="number">0.0</span>;</div><div class="line">    hranges[<span class="number">1</span>]= <span class="number">180.0</span>;</div><div class="line">    channels[<span class="number">0</span>]= <span class="number">0</span>; <span class="comment">// the hue channel</span></div><div class="line"></div><div class="line">       <span class="comment">// Compute histogram</span></div><div class="line">    cv::calcHist(&hsv, </div><div class="line">        <span class="number">1</span>,			<span class="comment">// histogram of 1 image only</span></div><div class="line">        channels,	<span class="comment">// the channel used</span></div><div class="line">        mask,	<span class="comment">// no mask is used</span></div><div class="line">        hist,		<span class="comment">// the resulting histogram</span></div><div class="line">        <span class="number">1</span>,			<span class="comment">// it is a 1D histogram</span></div><div class="line">        histSize,	<span class="comment">// number of bins</span></div><div class="line">        ranges		<span class="comment">// pixel value range</span></div><div class="line">    );</div><div class="line"></div><div class="line">    <span class="keyword">return</span> hist;</div><div class="line">}</div></pre></td></tr></table></figure></p>
<p>使用 <code>cv::meanshift()</code> 函数在两幅图像间跟踪某一物体的步骤如下：</p>
<ol>
<li>读入第一张图像，定义好目标跟踪窗口，即感兴趣区域 ROI 。</li>
<li>计算这个 ROI 的 Hue 通道的直方图；</li>
<li>读入第二张图像，转换到 HSV 颜色空间，并对其 Hue 分量进行阈值处理 <code>cv::threshold()</code>，去掉低饱和度的像素，以保证较高的饱和度；</li>
<li>应用 ROI 的 直方图信息对第 3 步得到的图像进行反投影变换；</li>
<li>对反投影变换的结果在进行一次按位与操作 <code>cv::bitwise_and()</code> ，去除结果中低饱和度的像素；</li>
<li>最后，对第 5 步得到的结果进行 meanshift 操作 <code>cv::meanShift()</code>，得到新的跟踪窗口。</li>
</ol>
<p>实现如下：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> main()</div><div class="line">{</div><div class="line">    <span class="comment">// Read reference image</span></div><div class="line">    cv::Mat image= cv::imread(<span class="string">"../baboon1.jpg"</span>);</div><div class="line">    <span class="keyword">if</span> (!image.data)</div><div class="line">        <span class="keyword">return</span> <span class="number">0</span>; </div><div class="line"></div><div class="line">    <span class="comment">// Define ROI</span></div><div class="line">    cv::Mat imageROI= image(cv::Rect(<span class="number">110</span>,<span class="number">260</span>,<span class="number">35</span>,<span class="number">40</span>));</div><div class="line">    cv::rectangle(image, cv::Rect(<span class="number">110</span>,<span class="number">260</span>,<span class="number">35</span>,<span class="number">40</span>), cv::Scalar(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>));</div><div class="line"></div><div class="line">    <span class="comment">// Display image</span></div><div class="line">    cv::namedWindow(<span class="string">"Image 1"</span>);</div><div class="line">    cv::imshow(<span class="string">"Image 1"</span>,image);</div><div class="line"></div><div class="line">    <span class="comment">// Get the Hue histogram</span></div><div class="line">    <span class="keyword">int</span> minSat=<span class="number">65</span>;</div><div class="line">    ColorHistogram hc;</div><div class="line">    cv::MatND colorhist= hc.getHueHistogram(imageROI, minSat);</div><div class="line"></div><div class="line">    ObjectFinder finder;</div><div class="line">    finder.setHistogram(colorhist);</div><div class="line">    finder.setThreshold(<span class="number">0.2f</span>);</div><div class="line"></div><div class="line">    <span class="comment">// Second image</span></div><div class="line">    image= cv::imread(<span class="string">"../baboon3.jpg"</span>);</div><div class="line"></div><div class="line"> 	<span class="comment">// Display image</span></div><div class="line">    cv::namedWindow(<span class="string">"Image 2"</span>);</div><div class="line">    cv::imshow(<span class="string">"Image 2"</span>,image);</div><div class="line"></div><div class="line">    <span class="comment">// Convert to HSV space</span></div><div class="line">    cv::Mat hsv;</div><div class="line">    cv::cvtColor(image, hsv, CV_BGR2HSV);</div><div class="line"></div><div class="line">    <span class="comment">// Split the image</span></div><div class="line">    <span class="stl_container"><span class="built_in">vector</span>&lt;cv::Mat&gt;</span> v;</div><div class="line">    cv::split(hsv,v);</div><div class="line"></div><div class="line">    <span class="comment">// Eliminate pixels with low saturation</span></div><div class="line">    cv::threshold(v[<span class="number">1</span>],v[<span class="number">1</span>],minSat,<span class="number">255</span>,cv::THRESH_BINARY);</div><div class="line">    cv::namedWindow(<span class="string">"Saturation"</span>);</div><div class="line">    cv::imshow(<span class="string">"Saturation"</span>,v[<span class="number">1</span>]);</div><div class="line"></div><div class="line">    <span class="comment">// Get back-projection of hue histogram</span></div><div class="line">    <span class="keyword">int</span> ch[<span class="number">1</span>]={<span class="number">0</span>};</div><div class="line">    cv::Mat result= finder.find(hsv,<span class="number">0.0f</span>,<span class="number">180.0f</span>,ch,<span class="number">1</span>);</div><div class="line"></div><div class="line">    cv::namedWindow(<span class="string">"Result Hue"</span>);</div><div class="line">    cv::imshow(<span class="string">"Result Hue"</span>,result);</div><div class="line"></div><div class="line">    <span class="comment">// Eliminate low stauration pixels</span></div><div class="line">    cv::bitwise_and(result,v[<span class="number">1</span>],result);</div><div class="line">    cv::namedWindow(<span class="string">"Result Hue and raw"</span>);</div><div class="line">    cv::imshow(<span class="string">"Result Hue and raw"</span>,result);</div><div class="line"></div><div class="line">    cv::Rect rect(<span class="number">110</span>,<span class="number">260</span>,<span class="number">35</span>,<span class="number">40</span>);</div><div class="line">    cv::rectangle(image, rect, cv::Scalar(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>));</div><div class="line"></div><div class="line">    cv::TermCriteria criteria(cv::TermCriteria::MAX_ITER,<span class="number">10</span>,<span class="number">0.01</span>);</div><div class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"meanshift= "</span> &lt;&lt; cv::meanShift(result,rect,criteria) &lt;&lt; endl;</div><div class="line"></div><div class="line">    cv::rectangle(image, rect, cv::Scalar(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>));</div><div class="line"></div><div class="line">    <span class="comment">// Display image</span></div><div class="line">    cv::namedWindow(<span class="string">"Image 2 result"</span>);</div><div class="line">    cv::imshow(<span class="string">"Image 2 result"</span>,image);</div><div class="line"></div><div class="line">    cv::waitKey();</div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">}</div></pre></td></tr></table></figure></p>
<p>《The OpenCV Reference Manual》里还建议再对反投影的结果进行降噪处理。例如，可以先使用 <code>cv::findContours()</code> 检索到一些闭合的轮廓边，使用 <code>cv::contourArea()</code> 去掉一些面积较小的轮廓边，再使用 <code>cv::drawContours()</code> 填充剩下的轮廓边。</p>
<h4 id="camshift">camshift</h4>
<p>camshift 是“continuously adaptive mean-shift”的缩写，顾名思义就是 mean-shift 的一个改进版本，它的实现基于 meanshift ，而与 meanshift 的最大区别在于窗口的大小和朝向是可变的。如果有一个易于分割的分布（例如保持紧密的人脸特征），此算法可以根据人在走近或远离摄像机时脸的尺寸而自动调整窗口的尺寸。</p>
<p>OpenCV 提供 <code>cv::Camshift()</code> 函数来进行 mean-shift 算法跟踪。</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">RotatedRect CamShift(InputArray probImage, Rect& window, TermCriteria criteria)</div></pre></td></tr></table></figure></p>
<p>该函数将返回一个经过旋转的矩形结构体 <code>RotatedRect</code> ，该结构体包含了目标的位置、大小和朝向信息。可以通过 <code>RotatedRect::boundingRect()</code> 函数获得查找窗口的下一个位置。</p>
<p><div class="alert alert-success"><i class="fa fa-lightbulb-o"></i>  <p>OpenCV 自带的示例程序中包含一个应用 camshift 捕捉彩色物体的示例 camshiftdemo.c 。</p>
</div></p>
<h2 id="特征匹配">特征匹配</h2>
<h3 id="harris-角点">Harris 角点</h3>
<h4 id="经典版本">经典版本</h4>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">void</span> cornerHarris(InputArray src,	<span class="comment">// input</span></div><div class="line">                OutputArray dst,	<span class="comment">// output</span></div><div class="line">                <span class="keyword">int</span> blockSize,	<span class="comment">// neighborhood size</span></div><div class="line">                <span class="keyword">int</span> ksize,		<span class="comment">// aperture size</span></div><div class="line">                <span class="keyword">double</span> k,			<span class="comment">// Harris parameter</span></div><div class="line">                <span class="keyword">int</span> borderType=BORDER_DEFAULT )</div></pre></td></tr></table></figure></p>
<p>示例：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Detect Harris Corners</span></div><div class="line">cv::Mat cornerStrength;</div><div class="line">cv::cornerHarris(image,cornerStrength,</div><div class="line">                <span class="number">3</span>,	<span class="comment">// neighborhood size</span></div><div class="line">                <span class="number">3</span>,	<span class="comment">// aperture size</span></div><div class="line">                <span class="number">0.01</span>); <span class="comment">// Harris parameter</span></div><div class="line"><span class="comment">// threshold the corner strengths</span></div><div class="line">cv::Mat harrisCorners;</div><div class="line"><span class="keyword">double</span> threshold= <span class="number">0.0001</span>;</div><div class="line">cv::threshold(cornerStrength,harrisCorners,</div><div class="line">            threshold,<span class="number">255</span>,cv::THRESH_BINARY_INV);</div></pre></td></tr></table></figure></p>
<p>原图：</p>
<p><img src="/images/opencv-video/2818iyC.png" alt=""></p>
<p>结果图：</p>
<p><img src="/images/opencv-video/2818v8I.png" alt=""></p>
<p>与原图结合：</p>
<p><img src="/images/opencv-video/2818wvn.png" alt=""></p>
<h4 id="改进版本">改进版本</h4>
<p>用上面的方法得到的 Harris 角点在图像中的分布不是很均匀，一个改进的方法是使用 <code>cv::goodFeaturesToTrack()</code> 方法（听名字就很彪悍），用它可以获得更加 strong 的角点：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">void</span> goodFeaturesToTrack(InputArray image,	<span class="comment">// input 8-bit or floating-point 32-bit, single-channel image</span></div><div class="line">                        OutputArray corners,	<span class="comment">// output vector of detected corners.</span></div><div class="line"></div><div class="line">                        <span class="keyword">int</span> maxCorners,		<span class="comment">// maximum number of corners to return</span></div><div class="line">                        <span class="keyword">double</span> qualityLevel,	<span class="comment">// quality level</span></div><div class="line">                        <span class="keyword">double</span> minDistance,	<span class="comment">// minimum allowed distance between points</span></div><div class="line">                        InputArray mask=noArray(),<span class="comment">// optional region of interest</span></div><div class="line">                        <span class="keyword">int</span> blockSize=<span class="number">3</span>,		<span class="comment">// size of an average block</span></div><div class="line">                        <span class="keyword">bool</span> useHarrisDetector=<span class="keyword">false</span>, <span class="comment">//  whether to use a classical Harris detector </span></div><div class="line">                        <span class="keyword">double</span> k=<span class="number">0.04</span> )		<span class="comment">// free parameter of the Harris detector</span></div></pre></td></tr></table></figure></p>
<p>示例：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Compute good features to track</span></div><div class="line">std::<span class="stl_container"><span class="built_in">vector</span>&lt;cv::Point2f&gt;</span> corners;</div><div class="line">cv::goodFeaturesToTrack(imaeg, corners,</div><div class="line">                        <span class="number">500</span>,	<span class="comment">// maximum number of corners to return</span></div><div class="line">                        <span class="number">0.01</span>,	<span class="comment">// quality level</span></div><div class="line">                        <span class="number">10</span>);	<span class="comment">// minimum allowed distance between points</span></div></pre></td></tr></table></figure></p>
<p>结果：</p>
<p><img src="/images/opencv-video/281895t.png" alt=""></p>
<p>这种方法得到的 Harris 角点在分布均匀程度上得到了很明显的改进。不过，这种改进的方案计算复杂度也更高，因为它需要对检测到的特征点按照 Harris 得分进行排序。另外，如果把第 8 个参数 <code>useHarrisDetector</code> 的值设为 true，则用的将是经典的 Harris 检测器。</p>
<h4 id="通用接口">通用接口</h4>
<p>为了方便使用这些特征检测算法，OpenCV 2 提供了特征点检测的通用接口，封装在抽象类 <code>cv::FeatureDetector</code> 里：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> CV_EXPORTS FeatureDetector</div><div class="line">{</div><div class="line">  <span class="keyword">public</span>:</div><div class="line">    <span class="keyword">virtual</span> ~FeatureDetector();</div><div class="line">    <span class="keyword">void</span> detect( <span class="keyword">const</span> Mat& image, <span class="stl_container"><span class="built_in">vector</span>&lt;KeyPoint&gt;</span>& keypoints,</div><div class="line">            <span class="keyword">const</span> Mat& mask=Mat() ) <span class="keyword">const</span>;</div><div class="line">    <span class="keyword">void</span> detect( <span class="keyword">const</span> <span class="stl_container"><span class="built_in">vector</span>&lt;Mat&gt;</span>& images,</div><div class="line">            <span class="stl_container"><span class="built_in">vector</span>&lt;<span class="stl_container"><span class="built_in">vector</span>&lt;KeyPoint&gt;</span> &gt;</span>& keypoints,</div><div class="line">            <span class="keyword">const</span> <span class="stl_container"><span class="built_in">vector</span>&lt;Mat&gt;</span>& masks=<span class="stl_container"><span class="built_in">vector</span>&lt;Mat&gt;</span>() ) <span class="keyword">const</span>;</div><div class="line">    <span class="keyword">virtual</span> <span class="keyword">void</span> read(<span class="keyword">const</span> FileNode&);</div><div class="line">    <span class="keyword">virtual</span> <span class="keyword">void</span> write(FileStorage&) <span class="keyword">const</span>;</div><div class="line">    <span class="keyword">static</span> Ptr&lt;FeatureDetector&gt; create( <span class="keyword">const</span> <span class="built_in">string</span>& detectorType );</div><div class="line">  <span class="keyword">protected</span>:</div><div class="line">...</div><div class="line">};</div></pre></td></tr></table></figure></p>
<p>其中：</p>
<ul>
<li><code>create()</code> 函数用于创建一个特征检测器，其参数 <code>detectorType</code> 可以是以下几种：
<ul>
<li>“FAST” – FastFeatureDetector</li>
<li>“STAR” – StarFeatureDetector</li>
<li>“SIFT” – SIFT (nonfree module)</li>
<li>“SURF” – SURF (nonfree module)</li>
<li>“ORB” – ORB</li>
<li>“BRISK” – BRISK</li>
<li>“MSER” – MSER</li>
<li>“GFTT” – GoodFeaturesToTrackDetector</li>
<li>“HARRIS” – GoodFeaturesToTrackDetector with Harris detector enabled</li>
<li>“Dense” – DenseFeatureDetector</li>
<li>“SimpleBlob” – SimpleBlobDetector</li>
</ul>
</li>
<li>两个 <code>detect()</code> 函数用于进行特征点检测；</li>
<li><code>read()</code> 和 <code>write()</code> 函数用于将检测到的特征点进行文件读/写。</li>
</ul>
<p>为了方便存储不同的特征点的信息，OpenCV 还为这个接口还定义了一个 <code>Keypoint</code> 类，用于存储特征点的所有相关属性。例如，对于 Harris 角点，该类的实例将会用来储存检测得到的特征点的位置。</p>
<p>另外，OpenCV 为每种特征点提供了从 <code>cv::FeatureDetector</code> 继承而来的子类。例如，改进的 Harris 角点对应子类 <code>cv::GoodFeatureToTrackDetector</code> 。使用方法如下：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// vector of keypoints</span></div><div class="line">std::<span class="stl_container"><span class="built_in">vector</span>&lt;cv::KeyPoint&gt;</span> keypoints;</div><div class="line"><span class="comment">// Construction of the Good Feature to Track detector</span></div><div class="line">cv::GoodFeatureToTrackDetector gftt (</div><div class="line">    <span class="number">500</span>,	<span class="comment">// maximum number of corners to be returned</span></div><div class="line">    <span class="number">0.01</span>,	<span class="comment">// quality level</span></div><div class="line">    <span class="number">10</span>);	<span class="comment">// minimum allowed distance between points</span></div><div class="line"><span class="comment">// point detection using FeatureDetector method</span></div><div class="line">gftt.detect(image, keypoints);</div></pre></td></tr></table></figure></p>
<p>OpenCV 还提供了一个通用方法 <code>cv::drawKeyPoints</code> 用于在图像上绘制得到的特征点：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">cv::drawKeyPoints(image,		<span class="comment">// original image</span></div><div class="line">                keypoints,	<span class="comment">// vector of keypoints</span></div><div class="line">                image,		<span class="comment">// the output image</span></div><div class="line">                cv::Scalar(<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), <span class="comment">// keypoint color</span></div><div class="line">                cv::DrawMatchesFlags::DRAW_OVER_OUTIMG); <span class="comment">// drawing flag</span></div></pre></td></tr></table></figure></p>
<p>这些类的使用方法大同小异。</p>
<h3 id="fast-特征点">FAST 特征点</h3>
<p>FAST 特征点是为了提高检测速度而设计的。使用示例：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// vector of keypoints</span></div><div class="line">std::<span class="stl_container"><span class="built_in">vector</span>&lt;cv::KeyPoint&gt;</span> keypoints;</div><div class="line"><span class="comment">// Construction of the Fast feature detector object</span></div><div class="line">cv::FastFeatureDetector fast(</div><div class="line">    <span class="number">40</span>);	<span class="comment">// threshold for detection</span></div><div class="line"><span class="comment">// feature point detection</span></div><div class="line">fast.detect(image, keypoints);</div><div class="line"><span class="comment">// Draw key points</span></div><div class="line">cv::drawKeyPoints(image,		<span class="comment">// original image</span></div><div class="line">                keypoints,	<span class="comment">// vector of keypoints</span></div><div class="line">                image,		<span class="comment">// the output image</span></div><div class="line">                cv::Scalar(<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), <span class="comment">// keypoint color</span></div><div class="line">                cv::DrawMatchesFlags::DRAW_OVER_OUTIMG); <span class="comment">// drawing flag</span></div></pre></td></tr></table></figure></p>
<p><img src="/images/opencv-video/2818KE0.png" alt=""></p>
<h3 id="surf-特征点">SURF 特征点</h3>
<p>SURF（Speeded Up Robust Features） 特征点是一种尺度不变，且运算效率快的特征点。</p>
<p>示例：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// vector of keypoints</span></div><div class="line">std::<span class="stl_container"><span class="built_in">vector</span>&lt;cv::KeyPoint&gt;</span> keypoints;</div><div class="line"><span class="comment">// Construct the SURF feature detector object</span></div><div class="line">cv::SurfFeatureDetector surf(</div><div class="line">    <span class="number">2500.</span>);	<span class="comment">// threshold</span></div><div class="line"><span class="comment">// Detect the SURF features</span></div><div class="line">surf.detect(image, keypoints);</div><div class="line"><span class="comment">// Draw the keypoints with scale and orientation information</span></div><div class="line">cv::drawKeypoints(image,	<span class="comment">// original image</span></div><div class="line">                keypoints,  <span class="comment">// vector of keypoints</span></div><div class="line">                featureImage, <span class="comment">// the resulting image</span></div><div class="line">                cv::Scalar(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>), <span class="comment">// color of the points</span></div><div class="line">                cv::DrawMatchesFlags::DRAW_RICH_KEYPOINTS); <span class="comment">//flag</span></div></pre></td></tr></table></figure></p>
<p><img src="/images/opencv-video/2818JYJ.png" alt=""></p>
<p>对另一幅尺度不同的图使用 SURF 特征检测，得到结果如下：</p>
<p><img src="/images/opencv-video/2818WiP.png" alt=""></p>
<p>仔细对比两幅图，可以发现当图像的尺度发生变化后，两幅图像存在对应的圆圈也会跟着改变大小。尽管不是全部特征点都有对应，但通常存在对应的特征点的数量已经足够用在两幅图像间的比配。</p>
<h3 id="sift-特征点">SIFT 特征点</h3>
<p>SURF 的一个发展是另一个著名的特征点 —— SIFT (Scale-Invariant Feature Transform) 。</p>
<p>使用示例：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// vector of keypoints</span></div><div class="line">std::<span class="stl_container"><span class="built_in">vector</span>&lt;cv::KeyPoint&gt;</span> keypoints;</div><div class="line"><span class="comment">// Construct the SURF feature detector object</span></div><div class="line">cv::SiftFeatureDetector sift{</div><div class="line">    <span class="number">0.03</span>,	<span class="comment">// feature threshold</span></div><div class="line">    <span class="number">10.</span>);	<span class="comment">// threshold to reduce</span></div><div class="line">            <span class="comment">// sensitivity to lines</span></div><div class="line">    <span class="comment">// Detect the SURF features</span></div><div class="line">    sift.detect(image, keypoints);</div><div class="line">}</div></pre></td></tr></table></figure></p>
<p>结果和 SURF 提取的结果很相似：</p>
<p><img src="/images/opencv-video/2818jsV.png" alt=""></p>
<p>SIFT 特征点比 SURF 更精确，不过速度上也慢一些。</p>
<h3 id="特征匹配-v2">特征匹配</h3>
<p>特征点的一大用处是用来进行特征匹配，例如寻找同个场景在两个不同角度的照片的对应关系。</p>
<p>在特征匹配中，特征描述子（feature descriptors）通常是一个用于描述一个特征点的 N 维向量，且在理想情况下该向量可以对光照的变化和小幅度的形变具有不变性。另外，描述子的好坏还可以通过一个距离方程（例如欧氏距离）来比较和度量。因此，特征描述子是特征匹配算法中的一个强有力的工具。</p>
<p>同样，OpenCV 2 提供了一个通用的接口类 <code>cv::DescriptorExtractor</code> 用于构造特征描述子：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> CV_EXPORTS DescriptorExtractor</div><div class="line">{</div><div class="line">  <span class="keyword">public</span>:</div><div class="line">    <span class="keyword">virtual</span> ~DescriptorExtractor();</div><div class="line">    <span class="keyword">void</span> compute( <span class="keyword">const</span> Mat& image, <span class="stl_container"><span class="built_in">vector</span>&lt;KeyPoint&gt;</span>& keypoints,</div><div class="line">                Mat& descriptors ) <span class="keyword">const</span>;</div><div class="line">    <span class="keyword">void</span> compute( <span class="keyword">const</span> <span class="stl_container"><span class="built_in">vector</span>&lt;Mat&gt;</span>& images, <span class="stl_container"><span class="built_in">vector</span>&lt;<span class="stl_container"><span class="built_in">vector</span>&lt;KeyPoint&gt;</span> &gt;</span>& keypoints,</div><div class="line">    <span class="stl_container"><span class="built_in">vector</span>&lt;Mat&gt;</span>& descriptors ) <span class="keyword">const</span>;</div><div class="line">    <span class="keyword">virtual</span> <span class="keyword">void</span> read( <span class="keyword">const</span> FileNode& );</div><div class="line">    <span class="keyword">virtual</span> <span class="keyword">void</span> write( FileStorage& ) <span class="keyword">const</span>;</div><div class="line">    <span class="keyword">virtual</span> <span class="keyword">int</span> descriptorSize() <span class="keyword">const</span> = <span class="number">0</span>;</div><div class="line">    <span class="keyword">virtual</span> <span class="keyword">int</span> descriptorType() <span class="keyword">const</span> = <span class="number">0</span>;</div><div class="line">    <span class="keyword">static</span> Ptr&lt;DescriptorExtractor&gt; create( <span class="keyword">const</span> <span class="built_in">string</span>& descriptorExtractorType );</div><div class="line">  <span class="keyword">protected</span>:</div><div class="line">...</div><div class="line">};</div></pre></td></tr></table></figure></p>
<p>其中：</p>
<ul>
<li><code>create()</code> 函数用于创建一个特征描述子，其参数 <code>detectorType</code> 可以是以下几种：
<ul>
<li>“SIFT” – SIFT</li>
<li>“SURF” – SURF</li>
<li>“ORB” – ORB</li>
<li>“BRISK” – BRISK</li>
<li>“BRIEF” – BriefDescriptorExtractor</li>
</ul>
</li>
<li>两个 <code>compute()</code> 函数用于从一组检测得到的特征点计算特征描述子；</li>
<li><code>read()</code> 和 <code>write()</code> 函数用于将检测到的特征点进行文件读/写；</li>
</ul>
<p>示例：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Construction of the SURF descriptor extractor</span></div><div class="line">cv::SurfDescriptorExtractor surfDesc;</div><div class="line"><span class="comment">// Extraction of the SURF descriptors</span></div><div class="line">cv::Mat descriptors1;</div><div class="line">surfDesc.compute(image1,keypoints1,descriptors1);</div></pre></td></tr></table></figure></p>
<p>结果是一个行数和特征点数量相同的矩阵，每一行都是一个 N 维 的描述子的 vector （以 SURF 描述子为例，N 默认为 64） 。每个 vector 可以很好的描述一个特征点周围的色值信息。两个特征点越相似，则它们的特征描述子越接近。</p>
<p>特征描述子在图像匹配中尤其有用。OpenCV 提供了一个最基本的匹配算法 <code>cv::BruteForceMatcher()</code> ，用法如下：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Construction of the matcher</span></div><div class="line">cv::BruteForceMatcher&lt;cv::L2&lt;<span class="keyword">float</span>&gt;&gt; matcher;</div><div class="line"><span class="comment">// Match the two image descriptors</span></div><div class="line">std::<span class="stl_container"><span class="built_in">vector</span>&lt;cv::DMatch&gt;</span> matches;</div><div class="line">matcher.match(descriptors1,descriptors2, matches);</div></pre></td></tr></table></figure></p>
<p>同样，OpenCV 也提供了一个通用接口类 <code>cv::DescriptorMatcher</code> ，封装了多种匹配方法。</p>
<p>得到的匹配结果是一个 <code>cv::DMatch</code> 类型的数据结构，这个结构体是一种 <a href="/wiki/cpp-container.html#pair-%E7%B1%BB%E5%9E%8B">pair 类型</a> ，每一个 pair 分别包含第一个 vector 和第二个 vector 的匹配到的元素的序号。</p>
<p>OpenCV 也提供了函数用于绘制匹配结果 <code>cv::drawMatches</code> ，下面示例将上面的代码得到的结果的前 25 个配对给绘制出来：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">std::nth_element(matches.begin(),	<span class="comment">// initial position</span></div><div class="line">                matches.begin()+<span class="number">24</span>, <span class="comment">// position of the sorted element</span></div><div class="line">                matches.end());	<span class="comment">// end position</span></div><div class="line"><span class="comment">// remove all elements after the 25th</span></div><div class="line">matches.erase(matches.begin()+<span class="number">25</span>, matches.end());</div><div class="line"><span class="comment">// Visualize matches</span></div><div class="line">cv::Mat imageMatches;</div><div class="line">cv::drawMatches(</div><div class="line">    image1,keypoints1,	<span class="comment">// 1st image and its keypoints</span></div><div class="line">    image2,keypoints2,	<span class="comment">// 2nd image and its keypoints</span></div><div class="line">    matches,				<span class="comment">// the matches</span></div><div class="line">    imageMatches,			<span class="comment">// the image produced</span></div><div class="line">    cv::Scalar(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>));   <span class="comment">// color of the lines</span></div></pre></td></tr></table></figure></p>
<p>结果如下：</p>
<p><img src="/images/opencv-video/2818w2b.png" alt=""></p>
<h2 id="相机校正">相机校正</h2>
<h3 id="畸变的由来">畸变的由来</h3>
<p>计算机视觉领域使用的相机模型称为针孔相机模型（pin-hole camera）：</p>
<p><img src="/images/opencv-video/855MKX.png" alt="理想的针孔相机"></p>
<p>基本的投影方程如下：</p>
<p>\[ h_i = f\frac{h_o}{d_o} \]</p>
<p>其中，图像的大小 （\(h_i\)） 与物体的大小 （\(h_o\)） 沿着与焦点的距离 （\(d_o\)） 成比例关系。</p>
<p>根据前面所提的背景知识，我们可以清楚地认识到在针孔相机模型里的关键参数就是相机的焦距和它的成像大小。另外，因为我们要处理的是数字图像，相机的像素数量也是一个相机的另一个重要参数。最后，为了计算场景中的一点在像素坐标中的位置，我们还需要一个额外的信息：考虑那条从焦点引出的与成像平面垂直的直线，我们需要知道这条线穿入成像平面的哪个像素点，这个点称为 <strong>主要点</strong> （principal point）。逻辑上，这个主要点应该设在成像平面的中心，但实际上这个点往往会由于机械原因，难免会偏移一些像素，这就是畸变的由来。</p>
<p><img src="/images/opencv-video/855_GF.png" alt="带有畸变的针孔相机"></p>
<h3 id="校正方法">校正方法</h3>
<h4 id="检测棋盘角点">检测棋盘角点</h4>
<p>对相机进行畸变校正的主要思想是给相机展示一些三维空间间位置已知的点，之后寻找这些点在图像上的相应投影位置，最后根据这些对应关系计算相机的相关信息。OpenCV 建议通过从不同角度获取一个棋盘模板图像来校正相机。在这个情况下，可以利用每张棋盘图像上的角点来获取实际位置和投影位置的对应关系，从而计算相机的相关信息。一个示例棋盘模板：</p>
<p><img src="/images/opencv-video/855ZUd.png" alt=""></p>
<p>从上面这张图也可以很明显的看出相机存在较严重的径向畸变（radial distortion），这种畸变现象在鱼眼镜头中非常普遍。</p>
<p>OpenCV 提供了一个自动检测棋盘模板中的角点的函数 <code>cv::findChessboardCorners()</code>：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">bool</span> findChessboardCorners(InputArray image,	<span class="comment">// source chessboard view</span></div><div class="line">                        Size patternSize,		<span class="comment">// number of inner corners per a chessboard row and column </span></div><div class="line">                        OutputArray corners,	<span class="comment">// output array of detected corners</span></div><div class="line">                        <span class="keyword">int</span> flags=CALIB_CB_ADAPTIVE_THRESH+CALIB_CB_NORMALIZE_IMAGE</div><div class="line">)</div></pre></td></tr></table></figure></p>
<p>调用它通常只需要提供一幅图像以及棋盘的大小信息（水平和竖直的内角点的数量，如上图中分别是 6 和 4），该方法会返回这些棋盘角点在图像中的位置：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// output vectors of image points</span></div><div class="line">std::<span class="stl_container"><span class="built_in">vector</span>&lt;cv::Point2f&gt;</span> imageCorners;</div><div class="line"><span class="comment">// number of corners on the chessboard</span></div><div class="line">cv::Size boardSize(<span class="number">6</span>, <span class="number">4</span>);</div><div class="line"><span class="comment">// Get the chessboard corners</span></div><div class="line"><span class="keyword">bool</span> found = cv::findChessboardCorners(image,</div><div class="line">                                    boardSize,</div><div class="line">                                    imageCorners);</div></pre></td></tr></table></figure></p>
<h4 id="绘制检测得到的结点">绘制检测得到的结点</h4>
<p>OpenCV 也提供了一个函数用于将检测到的结点画到棋盘图像上：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Draw the corners</span></div><div class="line">cv::drawChessboardCorners(image,</div><div class="line">                        boardSize, imageCorners,</div><div class="line">                        found);	<span class="comment">// corners have been found</span></div></pre></td></tr></table></figure></p>
<p><img src="/images/opencv-video/855mej.png" alt=""></p>
<p>这些角点间的线条可以表示这些角点在 vector 中的顺序。</p>
<h4 id="校正相机">校正相机</h4>
<p>当检测足够多不同角度的棋盘图像后（大概 10 ～ 20 张），就可以对相机进行校正了，OpenCV 提供了一个函数 <code>cv::calibrateCamera()</code> 进行校正：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">double</span> calibrateCamera(InputArrayOfArrays objectPoints,	<span class="comment">// a vector of vectors of calibration pattern points </span></div><div class="line">                        InputArrayOfArrays imagePoints,	<span class="comment">// a vector of vectors of the projections of calibration pattern points.</span></div><div class="line"></div><div class="line">                        Size imageSize,	<span class="comment">// size of the image</span></div><div class="line">                        InputOutputArray cameraMatrix,	<span class="comment">// output 3x3 floating-point camera matrix </span></div><div class="line">                        InputOutputArray distCoeffs,		<span class="comment">// output vector of distortion coefficients </span></div><div class="line">                        OutputArrayOfArrays rvecs,		<span class="comment">// output vector of rotation vectors </span></div><div class="line">                        OutputArrayOfArrays tvecs,		<span class="comment">// output vector of translation vectors e</span></div><div class="line">                        <span class="keyword">int</span> flags=<span class="number">0</span>,						<span class="comment">// flags</span></div><div class="line">                        TermCriteria criteria=TermCriteria( <span class="comment">// termination criteria</span></div><div class="line">                            TermCriteria::COUNT+TermCriteria::EPS,</div><div class="line">                            <span class="number">30</span>, DBL_EPSILON) )</div></pre></td></tr></table></figure></p>
<p>调用该函数将可以得到两个重要的输出：相机矩阵 <code>cameraMatrix</code> 和畸变系数 <code>distCoeffs</code> 。</p>
<p>为了方便，可以将上面的所有步骤封装成一个类 <a href="https://gist.github.com/9015477" target="_blank" rel="external">CameraCalibrator</a> ：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> CameraCalibrator {</div><div class="line"></div><div class="line">    <span class="comment">// input points</span></div><div class="line">    std::<span class="stl_container"><span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="stl_container"><span class="built_in">vector</span>&lt;cv::Point3f&gt;</span>&gt;</span> objectPoints;</div><div class="line">    std::<span class="stl_container"><span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="stl_container"><span class="built_in">vector</span>&lt;cv::Point2f&gt;</span>&gt;</span> imagePoints;</div><div class="line">    <span class="comment">// output Matrices</span></div><div class="line">    cv::Mat cameraMatrix;</div><div class="line">    cv::Mat distCoeffs;</div><div class="line">    <span class="comment">// flag to specify how calibration is done</span></div><div class="line">    <span class="keyword">int</span> flag;</div><div class="line">    <span class="comment">// used in image undistortion </span></div><div class="line">    cv::Mat map1,map2; </div><div class="line">    <span class="keyword">bool</span> mustInitUndistort;</div><div class="line"></div><div class="line">  <span class="keyword">public</span>:</div><div class="line">    CameraCalibrator() : flag(<span class="number">0</span>), mustInitUndistort(<span class="keyword">true</span>) {};</div><div class="line"></div><div class="line">    <span class="comment">// Open the chessboard images and extract corner points</span></div><div class="line">    <span class="keyword">int</span> addChessboardPoints(<span class="keyword">const</span> std::<span class="stl_container"><span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">string</span>&gt;</span>& filelist, cv::Size & boardSize);</div><div class="line">    <span class="comment">// Add scene points and corresponding image points</span></div><div class="line">    <span class="keyword">void</span> addPoints(<span class="keyword">const</span> std::<span class="stl_container"><span class="built_in">vector</span>&lt;cv::Point2f&gt;</span>& imageCorners, <span class="keyword">const</span> std::<span class="stl_container"><span class="built_in">vector</span>&lt;cv::Point3f&gt;</span>& objectCorners);</div><div class="line">    <span class="comment">// Calibrate the camera</span></div><div class="line">    <span class="keyword">double</span> calibrate(cv::Size &imageSize);</div><div class="line">    <span class="comment">// Set the calibration flag</span></div><div class="line">    <span class="keyword">void</span> setCalibrationFlag(<span class="keyword">bool</span> radial8CoeffEnabled=<span class="keyword">false</span>, <span class="keyword">bool</span> tangentialParamEnabled=<span class="keyword">false</span>);</div><div class="line">    <span class="comment">// Remove distortion in an image (after calibration)</span></div><div class="line">    cv::Mat remap(<span class="keyword">const</span> cv::Mat &image);</div><div class="line"></div><div class="line">    <span class="comment">// Getters</span></div><div class="line">    cv::Mat getCameraMatrix() { <span class="keyword">return</span> cameraMatrix; }</div><div class="line">    cv::Mat getDistCoeffs()   { <span class="keyword">return</span> distCoeffs; }</div><div class="line">};</div></pre></td></tr></table></figure></p>
<p>其中：</p>
<ul>
<li><code>addChessboardPoints()</code> 函数 - 用于读入一系列的棋盘图像并检测角点；</li>
<li><code>calibrate()</code> 函数 - 用于进行相机校正，得到相机的参数矩阵和畸变系数；</li>
<li><code>remap()</code> 函数 - 用于根据相机校正结果修复图像的畸变；</li>
<li><code>addPoints()</code> 函数 - <code>addChessboardPoints()</code> 在检测完角点后会调用这个函数。也可自己手动调用这个函数添加已知的角点位置和对应的空间坐标点。</li>
</ul>
<p>使用示例：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> main()</div><div class="line">{</div><div class="line"></div><div class="line">    cv::namedWindow(<span class="string">"Image"</span>);</div><div class="line">    cv::Mat image;</div><div class="line">    std::<span class="stl_container"><span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">string</span>&gt;</span> filelist;</div><div class="line"></div><div class="line">    <span class="comment">// generate list of chessboard image filename</span></div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=<span class="number">20</span>; i++) {</div><div class="line"></div><div class="line">        std::<span class="built_in">stringstream</span> str;</div><div class="line">        str &lt;&lt; <span class="string">"../chessboards/chessboard"</span> &lt;&lt; std::setw(<span class="number">2</span>) &lt;&lt; std::setfill(<span class="string">'0'</span>) &lt;&lt; i &lt;&lt; <span class="string">".jpg"</span>;</div><div class="line">        std::<span class="built_in">cout</span> &lt;&lt; str.str() &lt;&lt; std::endl;</div><div class="line"></div><div class="line">        filelist.push_back(str.str());</div><div class="line">        image= cv::imread(str.str(),<span class="number">0</span>);</div><div class="line">        cv::imshow(<span class="string">"Image"</span>,image);</div><div class="line">    </div><div class="line">         cv::waitKey(<span class="number">100</span>);</div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="comment">// Create calibrator object</span></div><div class="line">    CameraCalibrator cameraCalibrator;</div><div class="line">    <span class="comment">// add the corners from the chessboard</span></div><div class="line">    cv::Size boardSize(<span class="number">6</span>,<span class="number">4</span>);</div><div class="line">    cameraCalibrator.addChessboardPoints(</div><div class="line">        filelist,	<span class="comment">// filenames of chessboard image</span></div><div class="line">        boardSize);	<span class="comment">// size of chessboard</span></div><div class="line">        <span class="comment">// calibrate the camera</span></div><div class="line">    <span class="comment">//	cameraCalibrator.setCalibrationFlag(true,true);</span></div><div class="line">    cameraCalibrator.calibrate(image.size());</div><div class="line"></div><div class="line">    <span class="comment">// Image Undistortion</span></div><div class="line">    image = cv::imread(filelist[<span class="number">6</span>]);</div><div class="line">    cv::Mat uImage= cameraCalibrator.remap(image);</div><div class="line"></div><div class="line">    <span class="comment">// display camera matrix</span></div><div class="line">    cv::Mat cameraMatrix= cameraCalibrator.getCameraMatrix();</div><div class="line">    std::<span class="built_in">cout</span> &lt;&lt; <span class="string">" Camera intrinsic: "</span> &lt;&lt; cameraMatrix.rows &lt;&lt; <span class="string">"x"</span> &lt;&lt; cameraMatrix.cols &lt;&lt; std::endl;</div><div class="line">    std::<span class="built_in">cout</span> &lt;&lt; cameraMatrix.at&lt;<span class="keyword">double</span>&gt;(<span class="number">0</span>,<span class="number">0</span>) &lt;&lt; <span class="string">" "</span> &lt;&lt; cameraMatrix.at&lt;<span class="keyword">double</span>&gt;(<span class="number">0</span>,<span class="number">1</span>) &lt;&lt; <span class="string">" "</span> &lt;&lt; cameraMatrix.at&lt;<span class="keyword">double</span>&gt;(<span class="number">0</span>,<span class="number">2</span>) &lt;&lt; std::endl;</div><div class="line">    std::<span class="built_in">cout</span> &lt;&lt; cameraMatrix.at&lt;<span class="keyword">double</span>&gt;(<span class="number">1</span>,<span class="number">0</span>) &lt;&lt; <span class="string">" "</span> &lt;&lt; cameraMatrix.at&lt;<span class="keyword">double</span>&gt;(<span class="number">1</span>,<span class="number">1</span>) &lt;&lt; <span class="string">" "</span> &lt;&lt; cameraMatrix.at&lt;<span class="keyword">double</span>&gt;(<span class="number">1</span>,<span class="number">2</span>) &lt;&lt; std::endl;</div><div class="line">    std::<span class="built_in">cout</span> &lt;&lt; cameraMatrix.at&lt;<span class="keyword">double</span>&gt;(<span class="number">2</span>,<span class="number">0</span>) &lt;&lt; <span class="string">" "</span> &lt;&lt; cameraMatrix.at&lt;<span class="keyword">double</span>&gt;(<span class="number">2</span>,<span class="number">1</span>) &lt;&lt; <span class="string">" "</span> &lt;&lt; cameraMatrix.at&lt;<span class="keyword">double</span>&gt;(<span class="number">2</span>,<span class="number">2</span>) &lt;&lt; std::endl;</div><div class="line"></div><div class="line">    imshow(<span class="string">"Original Image"</span>, image);</div><div class="line">    imshow(<span class="string">"Undistorted Image"</span>, uImage);</div><div class="line"></div><div class="line">    cv::waitKey();</div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">}</div></pre></td></tr></table></figure></p>
<p>结果：</p>
<p><img src="/images/opencv-video/855N91.png" alt=""></p>
<h2 id="双目视觉">双目视觉</h2>
<h3 id="基本矩阵">基本矩阵</h3>
<h4 id="背景知识">背景知识</h4>
<p>通过两个摄像头在不同的角度同时捕获同个场景，可以获得场景的空间信息，这个技术称为双目视觉。</p>
<p>考虑两个相机观察同一个场景点：</p>
<p><img src="/images/opencv-video/855MRL.png" alt=""></p>
<p>由图可以看出，我们可以通过直接连接一个三维空间点 X 和左侧相机的中心点来找到其在左侧相机的成像中的位置 x 。反过来考虑，一个成像点 x 所对应的实际三维空间点的位置一定在这条直线上。这意味着，如果我们需要找到点 x 在第二台相机的成像位置 I’，我们需要找到第一条线在第二个相机的投影位置，这条线称为点 x 的 <strong>核线</strong> （epipolar line）。核线的角度取决于两个相机的相对位置。实际上，核线的位置与整个双目视觉系统的几何形状有关。</p>
<p>另一个可以观察得到的是所有核线都会经过一点 （图中的 e 或 e’），这个点是一个相机中心点在另一个相机的投影位置，这个特殊的点称为 <strong>核点</strong> （epipole）。</p>
<p>从数学角度上看，一个成像点和其对应的核线可以使用如下的 3x3 的矩阵来表示：</p>
<p>\[\begin{bmatrix} l'_{1} \\ l'_{2} \\ l'_{3} \end{bmatrix} = F \begin{bmatrix} x \\ y \\ 1 \end{bmatrix} \]</p>
<p>上面的公式表示一组 2D 点 \((x',y')\) 满足方程 \(l'_{1}x' + l'_{2}y' + l'_{3} = 0\) 。矩阵 F 称为 <strong>基本矩阵</strong> （fundamental matrix），可以将一个视点的 2D 图像点映射到另一个视点的核线上。</p>
<h4 id="计算方法">计算方法</h4>
<p>计算基本矩阵将是构建双目视觉系统的基础，方法是从两幅图像之间的若干已知配对点来计算一系列的方程。这些配对点可以使用<a href="#%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D">特征匹配</a>一节得到的配对结果。配对的最小数量是 7 。</p>
<p>OpenCV 提供了一个函数 <code>cv::findFundamentalMat()</code> 来计算基本矩阵：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Mat findFundamentalMat(InputArray points1,	<span class="comment">// array of N points from the first image</span></div><div class="line">                    InputArray points2,		<span class="comment">// array of N points from the second image.</span></div><div class="line">                    <span class="keyword">int</span> method=FM_RANSAC,		<span class="comment">// method for computing a fundamental matrix</span></div><div class="line">                    <span class="keyword">double</span> param1=<span class="number">3.</span>,			<span class="comment">// parameter used for RANSAC</span></div><div class="line">                    <span class="keyword">double</span> param2=<span class="number">0.99</span>,		<span class="comment">// parameter used for RANSAC or LMedS methods only</span></div><div class="line">                    OutputArray mask=noArray() )<span class="comment">// output array of N elements</span></div></pre></td></tr></table></figure></p>
<p>要使用这个函数，需要注意特征点的类型。<code>cv::findFundamentalMat</code> 接收的点的类型是 <code>cv::Point2F</code> ，因此对于通过特征匹配得到的 <code>cv::Keypoint</code> 类型的特征点，我们需要将它们转换成 <code>cv::Point2f</code> 类型：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Convert keypoints into Point2f</span></div><div class="line">std::<span class="stl_container"><span class="built_in">vector</span>&lt;cv::Point2f&gt;</span> selPoints1, selPoints2;</div><div class="line">cv::KeyPoint::convert(keypoints1, selPoints1, pointIndexes1);</div><div class="line">cv::KeyPoint::convert(keypoints2, selPoints2, pointIndexes1);</div></pre></td></tr></table></figure></p>
<p>两个 vector （selPoints1 和 selPoints2） 包含了两张图像中的配对点。之后调用 <code>cv::findFundamentalMat()</code> 函数如下：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Compute F matrix from 7 matches</span></div><div class="line">cv::Mat fundamental = cv::findFundamentalMat(</div><div class="line">    cv::Mat (selPoints1),	<span class="comment">// points in first image</span></div><div class="line">    cv::Mat (selPoints2),	<span class="comment">// points in second image</span></div><div class="line">    );</div></pre></td></tr></table></figure></p>
<p>可以将核线画出来，以验证基本矩阵的正确性。 OpenCV 提供了一个函数 <code>cv::computeCorrespondEpilines()</code> 来根据一些输入点和基本矩阵得到核线，之后就可以使用 <code>cv::line()</code> 函数将这些核线画出。示例：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// draw the left points corresponding epipolar</span></div><div class="line"><span class="comment">// lines in right image</span></div><div class="line">std::<span class="stl_container"><span class="built_in">vector</span>&lt;cv::Vec3f&gt;</span> lines1;</div><div class="line">cv::computeCorrespondEpilines(</div><div class="line">    cv::Mat(selPoints1), <span class="comment">// image points</span></div><div class="line">    <span class="number">1</span>,</div><div class="line">    <span class="comment">// in image 1 (can also be 2)</span></div><div class="line">    fundemental, <span class="comment">// F matrix</span></div><div class="line">    lines1);</div><div class="line"><span class="comment">// vector of epipolar lines</span></div><div class="line"><span class="comment">// for all epipolar lines</span></div><div class="line"><span class="keyword">for</span> (<span class="stl_container"><span class="built_in">vector</span>&lt;cv::Vec3f&gt;</span>::const_iterator it= lines1.begin();</div><div class="line">    it!=lines1.end(); ++it) {</div><div class="line">        <span class="comment">// draw the line between first and last column</span></div><div class="line">        cv::line(image2,</div><div class="line">        cv::Point(<span class="number">0</span>,-(*it)[<span class="number">2</span>]/(*it)[<span class="number">1</span>]),</div><div class="line">        cv::Point(image2.cols,-((*it)[<span class="number">2</span>]+</div><div class="line">            (*it)[<span class="number">0</span>]*image2.cols)/(*it)[<span class="number">1</span>]),</div><div class="line">            cv::Scalar(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>));</div><div class="line">}</div></pre></td></tr></table></figure></p>
<p>结果：</p>
<p><img src="/images/opencv-video/855ZbR.png" alt=""></p>
<p>图像中，所有的核线都会经过一点，这个点如前面所述就是核点，它是另一个相机中心点的投影。有时候，核点会落在图像的外面。</p>
<h3 id="双目图像匹配">双目图像匹配</h3>
<p>要进行图像匹配，之前已经给出了若干基于<a href="#%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D">特征匹配</a>的方法。但对于双目系统，存在可靠的特征匹配方法：当在两幅图像间进行特征匹配时，只接受落在对应的核线中的配对点。不过，要进行这个条件判断，先得计算基本矩阵，而基本矩阵又是根据配对点估算出来的。这看起来是一个先有鸡还是先有蛋的问题。下面介绍一种基于 RANSAC（RANdom SAmpling Consensus） 算法的配对算法，可以一边计算基本矩阵，一边寻找一组较优的配对点：</p>
<ol>
<li>检测特征点，并提取特征描述子；</li>
<li>使用K近邻算法配对特征点，先找出其第一幅图中每个特征点在第二幅图中最佳的两个配对，然后找出第二幅图中每个特征点在第一幅图中最佳的两个配对；</li>
<li>NN 率测试：对于每个特征点，如果其两个最佳配对点的描述子和该特征点的描述子非常接近，则这选择任何一个配对都可能导致错误，两组都不够优，因此将两组配对都移除；</li>
<li>对称性测试：对于每个特征点，如果它的描述子和第一个配对点的描述子距离很小，而和第二个配对点的描述子距离很大，那么可以判定第一个配对点更优，因此将第二个配对移除；</li>
<li>RANSAC测试：使用 RANSAC 算法来移除没有落在核线的特征点。RANSAC 是一种用来从一组包含 outliers 的数据中估算参数的迭代算法。在这里，我们每次随机采样 8 对配对点，计算其对应的基本矩阵并测试是否处于核线上，测试剩下的配对点构成了基本矩阵的支撑集。可想而知，如果一次随机取样的配对点包含错误，那么被删除的配对点就比较多，那么最后该支撑集就会比较小。迭代一定的次数后，我们从结果中挑出剩余配对点最多的，即最大的一个支撑集。</li>
</ol>
<p>可以使用一个封装好的 <a href="https://gist.github.com/9017475" target="_blank" rel="external">RobustMatcher</a> 类。其中：</p>
<ul>
<li><code>match()</code> 函数 - 核心匹配函数。返回匹配点、检测到的特征点和求得的基本矩阵；</li>
<li><code>ratioTest()</code> 函数 - 用于 NN 率测试；</li>
<li><code>symmetryTest()</code> 函数 - 用于对称性测试；</li>
<li><code>ransacTest()</code> 函数 - 用于 RANSAC 测试。</li>
</ul>
<p>示例：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Prepare the matcher</span></div><div class="line">RobustMatcher rmatcher;</div><div class="line">rmatcher.setConfidenceLevel(<span class="number">0.98</span>);</div><div class="line">rmatcher.setMinDistanceToEpipolar(<span class="number">1.0</span>);</div><div class="line">rmatcher.setRatio(<span class="number">0.65f</span>);</div><div class="line">cv::Ptr&lt;cv::FeatureDetector&gt; pfd=</div><div class="line">    <span class="keyword">new</span> cv::SurfFeatureDetector(<span class="number">10</span>);</div><div class="line">rmatcher.setFeatureDetector(pfd);</div><div class="line"><span class="comment">// Match the two images</span></div><div class="line">std::<span class="stl_container"><span class="built_in">vector</span>&lt;cv::DMatch&gt;</span> matches;</div><div class="line">std::<span class="stl_container"><span class="built_in">vector</span>&lt;cv::KeyPoint&gt;</span> keypoints1, keypoints2;</div><div class="line">cv::Mat fundemental= rmatcher.match(image1,image2,</div><div class="line">                    matches, keypoints1, keypoints2);</div></pre></td></tr></table></figure></p>
<p>对示例图片使用该算法后产生了 23 组配对，且这些都落在了核线上：</p>
<p><img src="/images/opencv-video/855mlX.png" alt=""></p>
<p>值得注意的是，该类默认使用 SURF 特征点，也可以很容易的通过 <code>setFeatureDetector()</code> 函数和 <code>setDescriptorExtractor()</code> 函数扩展其他类型的特征点：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Set the feature detector</span></div><div class="line"><span class="keyword">void</span> setFeatureDetector(</div><div class="line">    cv::Ptr&lt;cv::FeatureDetector&gt;& detect) {</div><div class="line">    detector= detect;</div><div class="line">}</div><div class="line"><span class="comment">// Set the descriptor extractor</span></div><div class="line"><span class="keyword">void</span> setDescriptorExtractor(</div><div class="line">cv::Ptr&lt;cv::DescriptorExtractor&gt;& desc) {</div><div class="line">    extractor= desc;</div><div class="line">}</div></pre></td></tr></table></figure></p>
<h3 id="单应矩阵">单应矩阵</h3>
<h4 id="基本知识">基本知识</h4>
<p>如果一个视点只是另一个视点的旋转，那么此时基本矩阵是无定义的，取而代之的，可以使用单应（Homography）矩阵来进行图像配对。和基本矩阵类似，单应矩阵也是一种可以从一对图像计算得到的矩阵，其大小也是 3x3 。单应矩阵揭示了一个视点的成像中的一点与另一个视点成像中的一点满足如下线性关系：</p>
<p>\[\begin{bmatrix} sx'\\ sy' \\ s \end{bmatrix} = H \begin{bmatrix} x \\ y \\ l \end{bmatrix} \]</p>
<p>其中， \(H\) 是该单应矩阵，\(s\) 是尺度因子。若算出了该单应矩阵，那么一个视点的成像中的所有点将可以根据这个式子找到其在另一个视点的成像中的位置。要注意，单应矩阵只在这种特殊情况下才存在。</p>
<h4 id="计算方法-v2">计算方法</h4>
<p>OpenCV 提供了 <code>cv::findHomography()</code> 函数用来计算单应矩阵：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Mat findHomography(InputArray srcPoints,</div><div class="line">                InputArray dstPoints,</div><div class="line">                <span class="keyword">int</span> method=<span class="number">0</span>,</div><div class="line">                <span class="keyword">double</span> ransacReprojThreshold=<span class="number">3</span>,</div><div class="line">                OutputArray mask=noArray() )</div></pre></td></tr></table></figure></p>
<p>在一个视点是另一个视点的旋转的情况下，同样可以使用前面提及的 RobustMatcher 类来进行图像配对，唯一的不同是在 RANSAC 测试中，计算基本矩阵改成了计算单应矩阵：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Find the homography between image 1 and image 2</span></div><div class="line">std::<span class="stl_container"><span class="built_in">vector</span>&lt;uchar&gt;</span> inliers(points1.size(),<span class="number">0</span>);</div><div class="line">cv::Mat homography= cv::findHomography(</div><div class="line">    cv::Mat(points1),	<span class="comment">// corresponding</span></div><div class="line">    cv::Mat(points2),	<span class="comment">// points</span></div><div class="line">    inliers,			<span class="comment">// outputted inliers matches</span></div><div class="line">    CV_RANSAC,		<span class="comment">// RANSAC method</span></div><div class="line">    <span class="number">1.</span>);				<span class="comment">// max distance to reprojection point</span></div></pre></td></tr></table></figure></p>
<p>得到的匹配点：</p>
<p><img src="/images/opencv-video/855zvd.png" alt=""></p>
<p><img src="/images/opencv-video/855A6j.png" alt=""></p>
<p>一旦得到了单应矩阵，我们可以很容易的确定图像中的一点在另一张图像中的位置。根据这个对应关系，我们可以把一张图从原来的视角变形到另一张图的视角：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Warp image 1 to image 2</span></div><div class="line">cv::Mat result;</div><div class="line">cv::warpPerspective(image1,	<span class="comment">// input image</span></div><div class="line">                    result,	<span class="comment">// output image</span></div><div class="line">                    homography, <span class="comment">// homography</span></div><div class="line">                    cv::Size(<span class="number">2</span>*image1.cols,</div><div class="line">                               image1.rows));	<span class="comment">// size of output image</span></div></pre></td></tr></table></figure></p>
<p>值得注意的是，默认得到的单应矩阵如果用来将第一张图的视角变到第二张图的视角，应该使用这个单应矩阵的逆矩阵。因此，<code>cv::warpPerspective()</code> 函数默认会先计算传入的单应矩阵的逆矩阵，然后用这个逆矩阵来变形。如果传入的矩阵已经是单应矩阵的逆矩阵，则可以在调用时指定 flag 参数为 <code>cv::WARP_INVERSE_MAP</code> 。</p>
<p>之后，可以把另一张图和这张已经处在同一视点的图拼接在一起：</p>
<p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Copy image 1 on the first half of full image</span></div><div class="line">cv::Mat half(result, cv::Rect(<span class="number">0</span>, <span class="number">0</span>, image2.cols, image2.rows));</div><div class="line">image2.copyTo(half);	<span class="comment">// copy image2 to image1 roi</span></div></pre></td></tr></table></figure></p>
<p>结果：</p>
<p><img src="/images/opencv-video/855nY2.png" alt=""></p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>这里用“稳定”这个形容词是指统计意义上的稳定，因为 mean-shift 忽略了数据中的 outliers ，即忽略远离数据峰值的点。mean-shift仅对数据局部窗口中的点进行处理，处理完成后再移动窗口。 <a href="#fnref1" class="footnote-backref">↩</a></p>
</li>
</ol>
</section>


		<!-- pagination -->
		<div>
		<center>
		<div class="pagination">
<ul class="pagination">
	
	
	
		
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
			
		
	
	    
			
		
	
	    
	
	    
	
	    
	
	    
			
		
	
	    
	
	    
			
			
		
	
	    
	
	    
			
			
			
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	    
	
	
		<li class="prev"><a data-pjax href="/wiki/opencv-image.html" class="alignleft prev"><i class="fa fa-arrow-circle-o-left"></i>Prev</a></li>
	
	<li><a data-pjax href="/wiki"><i class="fa fa-tasks"></i>Wiki</a></li>
	
		<li class="next"><a data-pjax href="/wiki/opencv-tables.html" class="alignright next">Next<i class="fa fa-arrow-circle-o-right"></i></a></li>
	
</ul>
</div>

	    </center>
		</div>
				
		<!-- toc -->
		
   	<script type="text/javascript">
		jQuery(document).ready(function() {
		
 		   generateWikiTOC('.note', '.toc',  2 , 2 );
		
		});
	</script>



				
		<!-- comment -->
		
<section id="comment">
    <h2 class="title">Comments</h2>
	
	 <div id="github-comment"></div>
	 <div id="loading-comment"></div>
	 <script type="text/javascript">
	   getComments({
	           github_user: "wzpan",
	           github_repo: "wzpan.github.io",
			   github_token: "0149f166735197952343b9f58d5bdc649567a8e1",
			   no_comment: "暂时还没有留言呢，点击下面的按钮去留言吧！",
			   go_to_comment: "去留言",
			   no_issue: "no_issue",
			   page_title: "视频处理",
			   issue_id: "undefined"
			   });
	 </script>
	
</section>


		

	</div> <!-- span9/span12 -->
</div><!-- row-fluid post-full -->

	</div>	
  </div>
  <div class="container-narrow">
  <footer> <p>
  &copy; 2017 Joseph Pan
  
      with help from <a href="http://zespia.tw/hexo/" target="_blank">Hexo</a> and 
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1254469760'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s95.cnzz.com/z_stat.php%3Fid%3D1254469760' type='text/javascript'%3E%3C/script%3E"));</script>
. 
    <small>
     <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/deed.zh"><img title="知识共享许可协议" style="border-width: 0px; vertical-align: middle; display: inline; " src="/images/license.png"></a>
    </small>
</p>
 </footer>
</div> <!-- container-narrow -->


<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/dist/jquery.imagesloaded.min.js"></script>


<script src="/dist/gallery.min.js"></script>
<script src="/dist/bootstrap.min.js"></script>
<script src="/dist/jquery.tableofcontents.min.js"></script>
<script src="/dist/tocgenerator.min.js"></script>
<script src="/dist/require.min.js"></script>
<script src="/dist/main.min.js"></script>


<script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>




<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v1/st.js','_st');

  _st('install','ney3Rb77vMaWT2KUKFyt');
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
        tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
        TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
        messageStyle: "none"
    }); 
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


</body>
</html>
